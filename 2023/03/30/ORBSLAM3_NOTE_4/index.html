<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>ORB-SLAM3源码阅读:ORBextractor | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="ORBSLAM3学习笔记(4)这篇博客主要是对ORBextractor.cc文件的学习，主要讲一下orb特征点提取的基本原理，还有相关函数代码的阅读。  基本原理1.关键点提取 关于关键点的选取比较简单，以某个像素为中心p，取周围16个像素点，近似一个圆。设置一个阈值T，假设这个点附近有N个点的亮度大于或者小于p的亮度+T或者p的亮度-T则认为这个点是特征点。 2.描述子获取描述子获取方面要用到o">
<meta property="og:type" content="article">
<meta property="og:title" content="ORB-SLAM3源码阅读:ORBextractor">
<meta property="og:url" content="http://example.com/2023/03/30/ORBSLAM3_NOTE_4/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="ORBSLAM3学习笔记(4)这篇博客主要是对ORBextractor.cc文件的学习，主要讲一下orb特征点提取的基本原理，还有相关函数代码的阅读。  基本原理1.关键点提取 关于关键点的选取比较简单，以某个像素为中心p，取周围16个像素点，近似一个圆。设置一个阈值T，假设这个点附近有N个点的亮度大于或者小于p的亮度+T或者p的亮度-T则认为这个点是特征点。 2.描述子获取描述子获取方面要用到o">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/3.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/4.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/5.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/cell.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/cell2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/DistributeOctTree.jpg">
<meta property="article:published_time" content="2023-03-30T05:55:07.000Z">
<meta property="article:modified_time" content="2023-05-18T07:35:45.686Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="ORBSLAM3 NOTE">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/1.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-ORBSLAM3_NOTE_4" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/03/30/ORBSLAM3_NOTE_4/" class="article-date">
  <time class="dt-published" datetime="2023-03-30T05:55:07.000Z" itemprop="datePublished">2023-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      ORB-SLAM3源码阅读:ORBextractor
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="ORBSLAM3学习笔记-4"><a href="#ORBSLAM3学习笔记-4" class="headerlink" title="ORBSLAM3学习笔记(4)"></a>ORBSLAM3学习笔记(4)</h1><p>这篇博客主要是对ORBextractor.cc文件的学习，主要讲一下orb特征点提取的基本原理，还有相关函数代码的阅读。</p>
<hr>
<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><h3 id="1-关键点提取"><a href="#1-关键点提取" class="headerlink" title="1.关键点提取"></a>1.关键点提取</h3><p><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/1.png" alt="Key points"></p>
<p>关于关键点的选取比较简单，以某个像素为中心p，取周围16个像素点，近似一个圆。设置一个阈值T，假设这个点附近有N个点的亮度大于或者小于p的亮度+T或者p的亮度-T则认为这个点是特征点。</p>
<h3 id="2-描述子获取"><a href="#2-描述子获取" class="headerlink" title="2.描述子获取"></a>2.描述子获取</h3><p>描述子获取方面要用到orb特征点的方向不变性，为了得到方向不变性，我们要计算关键点所在图像块的灰度质心，关键点方向就是关键点与图像块质心连接的向量。</p>
<p><strong>(1)灰度质心法原理</strong><br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/2.png" alt="图像块B"><br>该图是选取了关键点周围的图像块B(实际的图像块应该是圆形的，这里是为了方便讲解)，I(0,0)是关键点，以此图为例，介绍灰度质心法。</p>
<ul>
<li>选择某个图像块<em>B</em>，然后将图像块<em>B</em>的矩$m_{pq}$定义为:</li>
</ul>
<p>&ensp;&ensp;&ensp; $\sum_{x,y\in B}x^{p}y^{q}I(x, y),\qquad p,q&#x3D;{0, 1} $</p>
<ul>
<li>图像块<em>B</em>的质心可以通过公式中的矩找到：</li>
</ul>
<p>&ensp;&ensp;&ensp;&ensp;$C &#x3D;\left(\frac{m_{10}}{m_{00}},\frac{m_{01}}{m_{00}}\right)$</p>
<ul>
<li>方向向量$\overrightarrow{OC}$可以通过将图像块<em>B</em>的几何中心和它的质心连接在一起得到，所以可以定义特征点的方向$\theta$为：</li>
</ul>
<p>&ensp;&ensp;&ensp;&ensp;$\theta &#x3D; arctan(\frac{m_{01}}{m_{10}})$</p>
<p><strong>(2)方向不变性的使用</strong><br>首先，介绍一下BRIEF描述子，这一种二进制描述子，orbslam3中位数是128位，描述子的获取是通过在关键点周围选取128对点，比较这两个新点的像素值，前者大于后者d为0，前者小于后者d为1。</p>
<p>点对的选取是程序中默认给出的，若不考虑特征点方向，就可能出现一个问题，两帧图片之间是发生了旋转的，若直接选取点对，比如都选取点对(1,1)和(2,2),它们看似坐标一样，但在两幅图片中相对于特征点的位置是不一样的，那这样得到的描述子，进行匹配的时候，是没有参考意义的。</p>
<p>所以我们在获取每个关键点的描述子时，要根据之前得到的关键点方向$\theta$，把图片和所有点对旋转到与x轴平行，再进行点对比较。</p>
<p>旋转前坐标为$(x,y)$, 旋转后坐标$(x’,y’)$推导，$\theta$在求角度时得到，则<br>$x’&#x3D; xcos(θ) - ysin(θ),  y’&#x3D; xsin(θ) + ycos(θ)$</p>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="ORBextractor-ORBextractor"><a href="#ORBextractor-ORBextractor" class="headerlink" title="ORBextractor::ORBextractor()"></a>ORBextractor::ORBextractor()</h3><p>这是构造函数，主要是用来初始化成员变量，比较简单，我们就先在ORBextractor.h中看一下类的成员变量有哪些。</p>
<pre><code>std::vector&lt;cv::Point&gt; pattern;     

int nfeatures;      //指定要提取的特征点数目
double scaleFactor; //指定图像金字塔的缩放系数
int nlevels;        //指定图像金字塔的层数
int iniThFAST;      //指定初始的FAST特征点提取参数，可以提取出最明显的角点
int minThFAST;      //如果因为图像纹理不丰富提取出的特征点不多，为了达到想要的特征点数目，
                    //就使用这个参数提取出不是那么明显的角点

std::vector&lt;int&gt; mnFeaturesPerLevel;    //每层需要提取出来的特征点个数

std::vector&lt;int&gt; umax;

std::vector&lt;float&gt; mvScaleFactor;       //存储每层图像缩放系数
std::vector&lt;float&gt; mvInvScaleFactor;    //存储每层图像缩放系数的倒数
std::vector&lt;float&gt; mvLevelSigma2;       //存储每层图像相对初始图像缩放因子的平方
std::vector&lt;float&gt; mvInvLevelSigma2;    //存储每层图像相对初始图像缩放因子的平方的倒数
</code></pre>
<p>这些参数的功能都注释好了，现在看一下这些参数是如何初始化的。<br>nfeatures到minThFAST都是通过传递过来的参数赋值，这些参数是从配置文件中读取的。</p>
<p>mvScaleFactor到mvInvLevelSigma2都是根据nlevels确定向量长度，根据scaleFactor确定向量里面的内容，这些向量的第一个变量都是1，因为金字塔最底层是原始图像，不需要缩放。</p>
<p>mnFeaturesPerLevel是根据nfeatures得到的，nfeatures是我们一共要获得的特征点数量，我们从金字塔的每层（除最高层）选取一部分特征点，然后总数为nfeatures。其中第一层选取的个数如下：</p>
<pre><code>float nDesiredFeaturesPerScale = nfeatures*(1 - factor)/(1 - (float)pow((double)factor, (double)nlevels));
</code></pre>
<p>每上一层，取这个数层缩放比例的倒数。如果最后取到的特征点总数达不到nfeatures，那我们就在最高层取还差的数量。</p>
<p>pattern就是把按数组定义的点对坐标，存储到Point类型的向量中。</p>
<p>umax的作用和初始化我们根据下面的图和代码一起看<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/3.png" alt="umax"></p>
<pre><code>//下面的内容是和特征点的旋转计算有关的
//预先计算圆形patch中行的结束位置
//+1中的1表示那个圆的中间行
umax.resize(HALF_PATCH_SIZE + 1);

//cvFloor返回不大于参数的最大整数值，cvCeil返回不小于参数的最小整数值，cvRound则是四舍五入
int v,		//循环辅助变量
    v0,		//辅助变量
    vmax = cvFloor(HALF_PATCH_SIZE * sqrt(2.f) / 2 + 1);	//计算圆的最大行号，+1应该是把中间行也给考虑进去了
            //NOTICE 注意这里的最大行号指的是计算的时候的最大行号，此行的和圆的角点在45°圆心角的一边上，之所以这样选择
            //是因为圆周上的对称特性
            
//这里的二分之根2就是对应那个45°圆心角

int vmin = cvCeil(HALF_PATCH_SIZE * sqrt(2.f) / 2);
//半径的平方
const double hp2 = HALF_PATCH_SIZE*HALF_PATCH_SIZE;

//利用圆的方程计算每行像素的u坐标边界（max）
for (v = 0; v &lt;= vmax; ++v)
    umax[v] = cvRound(sqrt(hp2 - v * v));		//结果都是大于0的结果，表示x坐标在这一行的边界

// Make sure we are symmetric
//这里其实是使用了对称的方式计算上四分之一的圆周上的umax，目的也是为了保持严格的对称（如果按照常规的想法做，由于cvRound就会很容易出现不对称的情况，
//同时这些随机采样的特征点集也不能够满足旋转之后的采样不变性了）
for (v = HALF_PATCH_SIZE, v0 = 0; v &gt;= vmin; --v)
&#123;
    while (umax[v0] == umax[v0 + 1])
        ++v0;
    umax[v] = v0;
    ++v0;
&#125;
</code></pre>
<p>由于我们选取的图像块是圆形的(为了保证旋转不变性)，每行的像素个数不像矩形都是一样的，所以我们要存储每行像素的u坐标边界。HALF_PATCH_SIZE是定义好的全局变量，就是图像块的半径，大小为16。每行的umax通过勾股定理求得。</p>
<hr>
<h3 id="ORBextractor-operator"><a href="#ORBextractor-operator" class="headerlink" title="ORBextractor::operator()()"></a>ORBextractor::operator()()</h3><p>首先，我们先看传入的参数</p>
<pre><code>int ORBextractor::operator()(InputArray _image, //输入原始图的图像   
    InputArray _mask,                           //掩膜mask,为空，估计没什么用
    vector&lt;KeyPoint&gt;&amp; _keypoints,               //存储特征点关键点的向量
    OutputArray _descriptors,                   //存储特征点描述子的矩阵 
    std::vector&lt;int&gt; &amp;vLappingArea              //界限
    )
</code></pre>
<p>接下来，步骤如下:<br><strong>1.判断图像是否为空，是否为单通道</strong><br><strong>2.构建图像金字塔</strong></p>
<pre><code>ComputePyramid(image);
</code></pre>
<p><strong>3.计算图像的特征点，并且将特征点进行均匀化</strong></p>
<pre><code>// 存储所有的特征点，注意此处为二维的vector，第一维存储的是金字塔的层数，第二维存储的是那一层金字塔图像里提取的所有特征点
vector &lt; vector&lt;KeyPoint&gt; &gt; allKeypoints; 
//使用四叉树的方式计算每层图像的特征点并进行分配
ComputeKeyPointsOctTree(allKeypoints);
</code></pre>
<p>这里得到了金字塔每层均匀的特征点，且特征点都是带角度的。<br><strong>4.拷贝图像描述子到新的矩阵descriptors</strong><br>这里就是创建了一个Mat矩阵_descriptors，然后拷贝到传过来的参数descriptors中，这时descriptors中还没有数据。有一说一，感觉直接用descriptors创建也行，不用拷贝。</p>
<pre><code>//如果图像金字塔中有特征点，那么就创建这个存储描述子的矩阵，注意这个矩阵是存储整个图像金字塔中特征点的描述子的
_descriptors.create(nkeypoints,		//矩阵的行数，对应为特征点的总个数
                    32, 			//矩阵的列数，对应为使用32*8=256位描述子
                    CV_8U);			//矩阵元素的格式
//获取这个描述子的矩阵信息
descriptors = _descriptors.getMat();
</code></pre>
<p><strong>5.遍历图像金字塔的每一层，进行如下操作</strong><br>5-1.对图像进行高斯模糊<br>5-2.计算高斯模糊后图像的描述子，使用了函数computeDescriptors()，计算方法就是博客前面提到的，代码就不细看了。<br>5-3.对非第0层图像中的特征点的坐标恢复到第0层图像（原图像）的坐标系下,得到所有层特征点在第0层里的坐标放到_keypoints里面，描述子拷贝到descriptors中，特征点与其对应的描述子在vector容器中的位置是一样的。</p>
<hr>
<h3 id="ComputePyramid"><a href="#ComputePyramid" class="headerlink" title="ComputePyramid()"></a>ComputePyramid()</h3><pre><code>void ORBextractor::ComputePyramid(cv::Mat image)
&#123;
    //开始遍历所有的图层
    for (int level = 0; level &lt; nlevels; ++level)
    &#123;
        //获取本层图像的缩放系数
        float scale = mvInvScaleFactor[level];
        //计算本层图像的像素尺寸大小
        Size sz(cvRound((float)image.cols*scale), cvRound((float)image.rows*scale));
        //将图像进行“补边”，EDGE_THRESHOLD区域外的图像不进行FAST角点检测
        Size wholeSize(sz.width + EDGE_THRESHOLD*2, sz.height + EDGE_THRESHOLD*2);
        // 定义了两个变量：temp是扩展了边界的图像，masktemp并未使用
        Mat temp(wholeSize, image.type()), masktemp;
        // 把图像金字塔该图层的图像指针mvImagePyramid指向temp的中间部分（这里为浅拷贝，内存相同）
        mvImagePyramid[level] = temp(Rect(EDGE_THRESHOLD, EDGE_THRESHOLD, sz.width, sz.height));

        // Compute the resized image
        //计算第0层以上resize后的图像
        if( level != 0 )
        &#123;
            //将上一层金字塔图像根据设定sz缩放到当前层级
            resize(mvImagePyramid[level-1],	//输入图像
                mvImagePyramid[level], 	//输出图像
                sz, 				    //输出图像的尺寸
                0, 				        //水平方向上的缩放系数，留0表示自动计算
                0,  				    //垂直方向上的缩放系数，留0表示自动计算
                cv::INTER_LINEAR);		//图像缩放的差值算法类型，这里的是线性插值算法

            //这样做是为了能够正确提取边界的FAST角点		
            copyMakeBorder(mvImagePyramid[level], 	        //源图像
                        temp, 					            //目标图像（此时其实就已经有大了一圈的尺寸了）
                        EDGE_THRESHOLD, EDGE_THRESHOLD, 	//top &amp; bottom 需要扩展的border大小
                        EDGE_THRESHOLD, EDGE_THRESHOLD,		//left &amp; right 需要扩展的border大小
                        BORDER_REFLECT_101+BORDER_ISOLATED);//扩充方式
        &#125;
        else
        &#123;
            //对于第0层未缩放图像，直接将图像深拷贝到temp的中间，并且对其周围进行边界扩展。此时temp就是对原图扩展后的图像
            copyMakeBorder(image,			
                        temp, 
                        EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD,
                        BORDER_REFLECT_101);            
        &#125;
    &#125;
&#125;
</code></pre>
<p>这里主要先看temp和mvImagePyramid[level]，temp定义了一个带padding的图像，目的是:<br>1.利用FAST算法在提取特征点时，图像边缘的特征点半径为3的圆无法取到（边界外无像素点），需要扩展3个像素宽度的边缘。<br>2.计算描述子时，边缘的特征点需要半径为19的圆，故扩充的padding宽度EDGE_THRESHOLD&#x3D;19。</p>
<p>定义好变量后，接下来就是缩放图像，如果是第零层，那就直接把原始图像放到temp中间，完成一个带边框的图像，mvImagePyramid[level]指向中间部分。之后，就先把上一层的图像缩小后放入mvImagePyramid[level]中，然后copyMakeBorder函数用算法填充padding。这两步过后就有一个带padding的缩放好的图像了。具体图像样式如下所示。<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/4.png" alt="temp"><br>这就是temp图像，说实话，作者这里应该是有一个小bug,按作者本意，肯定是要有边框的图像的，但实际上mvImagePyramid[level]按上面讲的，还是只取了temp的中间部分，是无边框的。这样下面取角点的时候，就是把原图的边缘宽度为19的部分当作padding，这些当作padding的像素点就不能做角点检测了，不过这个padding相对于整块图片还是比较小的，总体损失不大。</p>
<hr>
<h3 id="ComputeKeyPointsOctTree"><a href="#ComputeKeyPointsOctTree" class="headerlink" title="ComputeKeyPointsOctTree()"></a>ComputeKeyPointsOctTree()</h3><p>我们先来理一下该方法的具体原理和流程。</p>
<p>提取特征点最重要的就是力求特征点均匀地分布在图像的所有部分,为实现这一目标,编程实现上使用了两个技巧:<br>1.分CELL搜索特征点,若某CELL内特征点响应值普遍较小的话就降低分数线再搜索一遍.<br>2.对得到的所有特征点进行八叉树筛选,若某区域内特征点数目过于密集,则只取其中响应值最大的那个。</p>
<p>代码运行流程如下:<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/5.png" alt=" ComputeKeyPointsOctTree"></p>
<p>下面具体看代码，主要看遍历网格部分，这段计算机视觉life的注释不太对，我改了一下</p>
<pre><code>//开始遍历图像网格，还是以行开始遍历的
for(int i=0; i&lt;nRows; i++)
&#123;
    //计算当前网格初始行坐标
    const float iniY =minBorderY+i*hCell;
    float maxY = iniY+hCell+6;

    //如果初始的行坐标就已经超过了有效的图像边界了，下一次循环
    if(iniY&gt;=maxBorderY-3)
        continue;
    //如果图像的大小导致不能够正好划分出来整齐的图像网格，那么就把提取特征点的区域缩小一些
    if(maxY&gt;maxBorderY)
        maxY = maxBorderY;

    //开始列的遍历
    for(int j=0; j&lt;nCols; j++)
    &#123;
        const float iniX =minBorderX+j*wCell;
        float maxX = iniX+wCell+6;				
        if(iniX&gt;=maxBorderX-3)
            continue;
        if(maxX&gt;maxBorderX)
            maxX = maxBorderX;

        //这个容器存储提取到的特征点
        vector&lt;cv::KeyPoint&gt; vKeysCell;

        //FAST提取特征点，调用opencv的库函数来检测FAST角点
        FAST(mvImagePyramid[level].rowRange(iniY,maxY).colRange(iniX,maxX),	//待检测的图像，这里就是当前遍历到的图像块
            vKeysCell,      //存储角点位置的容器
            iniThFAST,		//检测阈值
            true);			//使能非极大值抑制

        //如果这个图像块中使用默认的FAST检测阈值没有能够检测到角点
        if(vKeysCell.empty())
        &#123;
            //那么就使用更低的阈值来进行重新检测
            FAST(mvImagePyramid[level].rowRange(iniY,maxY).colRange(iniX,maxX),	//待检测的图像
                vKeysCell,		//存储角点位置的容器
                minThFAST,		//更低的检测阈值
                true);			//使能非极大值抑制
        &#125;

        //当图像cell中检测到FAST角点的时候执行下面的语句
        if(!vKeysCell.empty())
        &#123;
            //遍历其中的所有FAST角点
            for(vector&lt;cv::KeyPoint&gt;::iterator vit=vKeysCell.begin(); vit!=vKeysCell.end();vit++)
            &#123;
                //NOTICE 到目前为止，这些角点的坐标都是基于图像cell的，现在我们要先将其恢复到当前的【坐标边界】下的坐标
                //这样做是因为在下面使用八叉树法整理特征点的时候将会使用得到这个坐标
                //在后面将会被继续转换成为在当前图层的扩充图像坐标系下的坐标
                (*vit).pt.x+=j*wCell;
                (*vit).pt.y+=i*hCell;
                //然后将其加入到”等待被分配“的特征点容器中
                vToDistributeKeys.push_back(*vit);
            &#125;//遍历图像cell中的所有的提取出来的FAST角点，并且恢复其在整个金字塔当前层图像下的坐标
        &#125;
    &#125;
&#125;
</code></pre>
<p>最开始，就是对allKeypoints，cell的尺寸初始化，然后就开始遍历图像金字塔的每一层。遍历每次金字塔时，先定义我们要用到的图像边界minBorderX之类的，这些变量讲构建金字塔时，在图上都有标注。然后就是定义一些遍历cell时的一些辅助变量，之后就开始遍历图像网格了，这里要细讲一下。</p>
<p><strong>遍历图像网格</strong><br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/cell.png" alt="cell"><br>如图所示，虽然我们之前定义的cell应该是35x35的，但我们每次遍历的网格按上面的代码其实应该是41x41的，这是因为我们检测角点用的是opencv库里面的FAST()函数，该方法是以检测点为圆心建立半径为3的圆进行计算，由此图像四周要留出3像素的宽度，这样实际检测的就是35x35了。<br>根据上面的图，其实我们按窗口检测角点时，边缘3像素宽度位置的像素是无法检测的，但是我们窗口移动时，会包含这些像素。<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/cell2.png" alt="cell2"></p>
<p>网格全部遍历完后，将得到的角点存储到vToDistributeKeys中，此时特征点的坐标是扩充3个像素点的图像的坐标系下的，即上面图片绿色那部分。接下来，对提取到的特征点进行八叉树筛选,见 DistributeOctTree() 函数。</p>
<pre><code>//声明一个对当前图层的特征点的容器的引用
vector&lt;KeyPoint&gt; &amp; keypoints = allKeypoints[level];
//并且调整其大小为欲提取出来的特征点个数
keypoints.reserve(nfeatures);

// 根据mnFeatuvector&lt;KeyPoint&gt; &amp; keypoints = allKeypoints[level];resPerLevel,即该层的兴趣点数,对特征点进行剔除
//返回值是一个保存有特征点的vector容器，含有剔除后的保留下来的特征点
//得到的特征点的坐标，依旧是在当前图层下来讲的
keypoints = DistributeOctTree(vToDistributeKeys, 			//当前图层提取出来的特征点
                            minBorderX, maxBorderX,		    //当前图层图像的边界
                            minBorderY, maxBorderY,
                            mnFeaturesPerLevel[level], 	    //希望保留下来的当前层图像的特征点个数
                            level);						    //当前层图像所在的图层

//PATCH_SIZE是对于底层的初始图像来说的，现在要根据当前图层的尺度缩放倍数进行缩放得到缩放后的PATCH大小 和特征点的方向计算有关
const int scaledPatchSize = PATCH_SIZE*mvScaleFactor[level];

//获取剔除过程后保留下来的特征点数目
//然后开始遍历这些特征点，恢复其在当前图层图像坐标系下的坐标
for(int i=0; i&lt;nkps ; i++)
&#123;
    keypoints[i].pt.x+=minBorderX;
    keypoints[i].pt.y+=minBorderY;
    //记录特征点来源的图像金字塔图层
    keypoints[i].octave=level;
    //记录计算方向的patch，缩放后对应的大小， 又被称作为特征点半径
    keypoints[i].size = scaledPatchSize;
&#125;
</code></pre>
<p>这里的坐标恢复到了以最外层为坐标系，就是上面图片的最外面那一层，PATCH_SIZE就是使用灰度质心法计算特征点的方向信息时，图像块的大小,或者说是直径，要根据金字塔每层的大小进行缩放。</p>
<p>最后计算特征点方向</p>
<pre><code>for (int level = 0; level &lt; nlevels; ++level)
    computeOrientation(mvImagePyramid[level],	//对应的图层的图像
                       allKeypoints[level], 	//这个图层中提取并保留下来的特征点容器
                       umax);					//以及PATCH的横坐标边界
</code></pre>
<p>特征点角度计算的原理博客开头已经解释过了，就是用灰度质心法，不过上面讲解时用的是矩形图，实际应该用圆形，可以用成员变量umax来遍历圆形图像块。</p>
<hr>
<h3 id="ORBextractor-DistributeOctTree"><a href="#ORBextractor-DistributeOctTree" class="headerlink" title="ORBextractor::DistributeOctTree()"></a>ORBextractor::DistributeOctTree()</h3><p>函数DistributeOctTree()进行八叉树筛选(非极大值抑制),不断将存在特征点的图像区域进行4等分,直到分出了足够多的分区,每个分区内只保留响应值最大的特征点。<br>这里就不看代码了，知道原理就行，代码太长了，且比较繁琐，主要是看不看懂其实没差。</p>
<p><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/DistributeOctTree.jpg" alt="DistributeOctTree"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/03/30/ORBSLAM3_NOTE_4/" data-id="cll2ehamx000iks9f8w47hcqa" data-title="ORB-SLAM3源码阅读:ORBextractor" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ORBSLAM3-NOTE/" rel="tag">ORBSLAM3 NOTE</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/03/30/ORBSLAM3_NOTE_5/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          ORB-SLAM3源码阅读:LocalMapping
        
      </div>
    </a>
  
  
    <a href="/2023/03/28/ORBSLAM3_NOTE_3/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">ORB-SLAM3源码阅读:Tracking</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ORBSLAM3-NOTE/" rel="tag">ORBSLAM3 NOTE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VIO-NOTE/" rel="tag">VIO NOTE</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ORBSLAM3-NOTE/" style="font-size: 20px;">ORBSLAM3 NOTE</a> <a href="/tags/VIO-NOTE/" style="font-size: 10px;">VIO NOTE</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">March 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/05/18/VIO_NOTE_01/">VIO_NOTE_01</a>
          </li>
        
          <li>
            <a href="/2023/04/27/ORBSLAM3-NOTE-12/">ORB-SLAM3源码阅读:KeyFrameDatabase</a>
          </li>
        
          <li>
            <a href="/2023/04/13/ORBSLAM3-NOTE-11/">ORB-SLAM3源码阅读:MapPoint</a>
          </li>
        
          <li>
            <a href="/2023/04/13/ORBSLAM3-NOTE-10/">ORB-SLAM3源码阅读:KeyFrame</a>
          </li>
        
          <li>
            <a href="/2023/04/11/ORBSLAM3-NOTE-9/">ORB-SLAM3源码阅读:TwoViewReconstruction</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>