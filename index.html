<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://example.com/"/>





  <title>Hexo</title>
  








<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/09/09/VINSMONO-NOTE-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/09/09/VINSMONO-NOTE-2/" itemprop="url">VINS-MONO源码阅读:预积分</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-09-09T17:21:24+08:00">
                2023-09-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="VINSMONO学习笔记-2"><a href="#VINSMONO学习笔记-2" class="headerlink" title="VINSMONO学习笔记(2)"></a>VINSMONO学习笔记(2)</h1><p>这篇博客开始就是对功能包<code>estimator_node</code>的学习了，这篇会简单理一下这个功能包的脉络，然后重点把预积分部分的代码梳理清楚。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="main-函数"><a href="#main-函数" class="headerlink" title="main()函数"></a>main()函数</h3><p>main()函数中，首先调用函数readParameters(n)从yaml文件中读取相关参数，至于读了哪些参数等用到再解释。然后，estimator.setParameter()读取了每一个相机到IMU坐标系的旋转/平移外参数和非线性优化的重投影误差部分的信息矩阵。<strong><code>estimator</code>这个变量相当重要，之后基本都是对其进行操作，这里建议把他的缺省构造函数好好看一下。</strong><br>接下来，registerPub(n)发布用于RVIZ显示的Topic。然后就是定义了四个订阅方，接收对应的信息，并启动一个子线程调用函数<code>process()</code>。下面会着重讲回调函数<code>imu_callback()</code>和<code>process()</code>中涉及预积分的部分。</p>
<hr>
<h3 id="void-imu-callback"><a href="#void-imu-callback" class="headerlink" title="void imu_callback()"></a>void imu_callback()</h3><p>这个函数是只要接收到imu数据就会执行。首先，先更新最新的imu数据时间<code>last_imu_t</code>,往<code>imu_buf</code>里放IMU数据，缓存起来。con.notify_one()这句代码用处是每次执行后就会唤醒函数<code>process()</code>中的con.wait(…),执行该语句。这里的代码是要用到线程锁的，避免imu_buf存取数据冲突。</p>
<pre><code>last_imu_t = imu_msg-&gt;header.stamp.toSec();
m_buf.lock();
imu_buf.push(imu_msg);
m_buf.unlock();
con.notify_one();
last_imu_t = imu_msg-&gt;header.stamp.toSec();

&#123;
    std::lock_guard&lt;std::mutex&gt; lg(m_state);
    predict(imu_msg);
    std_msgs::Header header = imu_msg-&gt;header;
    header.frame_id = &quot;world&quot;;
    if (estimator.solver_flag == Estimator::SolverFlag::NON_LINEAR)
        pubLatestOdometry(tmp_P, tmp_Q, tmp_V, header);
&#125;
</code></pre><p>然后，执行函数predict(imu_msg)，该函数就是读取传来的imu数据，使用中值法求解PVQ，更新tmp_Q，tmp_P，tmp_V的值，然后更新acc_0和gyr_0，作为下一次中执法的初始值，具体公式如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/VINSMONO/中值法.png" alt="中值法"><br>这里的数据都是世界坐标系下的。其实未初始化时，这个函数虽然在跑，但得到的结果都是无效的，因为此时该函数里的<code>estimator.g</code>，<code>tmp_Ba</code>,<code>tmp_Bg</code>一直是(0,0,0)。<br>最后，如果当前处于非线性优化阶段的话，需要把predict函数计算得到的PVQ发布到rviz里去，见utility/visualization.cpp的pubLatestOdometry()函数。</p>
<hr>
<h3 id="void-process"><a href="#void-process" class="headerlink" title="void process()"></a>void process()</h3><p>1.获得measurements数据，首先先要看一下measurements的数据类型，还是挺复杂的。</p>
<pre><code>std::vector&lt;std::pair&lt;std::vector&lt;sensor_msgs::ImuConstPtr&gt;, sensor_msgs::PointCloudConstPtr&gt;&gt; measurements;
</code></pre><p><code>measurements</code>最外层看是一个向量容器，这个容器中存储一些数据对（std::pair），然后再看单个数据对，它的第一位也是一个容器，里面存放着一段时间下的imu数据，第二位存放的是一帧图像中的特征点数据，就是<code>feature_tracker_node</code>传过来的，至于具体怎么把数据放进measurements，这些数据又是怎么选取配对的，要看函数getMeasurements()，这个函数里主要就是有几个判断：</p>
<ul>
<li><strong>if (imu_buf.empty() || feature_buf.empty())</strong>，这个说明数据取完了，说明配对完成，直接返回；</li>
<li><strong>if (!(imu_buf.back()-&gt;header.stamp.toSec() &gt; feature_buf.front()-&gt;header.stamp.toSec() + estimator.td))</strong>，这里imu_buf里面所有数据的时间戳都比img buf第一个帧时间戳要早，说明缺乏IMU数据，需要等待IMU数据；</li>
<li><strong>if (!(imu_buf.front()-&gt;header.stamp.toSec() &lt; feature_buf.front()-&gt;header.stamp.toSec() + estimator.td))</strong>，IMU第一个数据的时间要大于第一个图像特征数据的时间，说明有图像帧太老了，讲<code>feature_buf</code>中的数据pop出一个，然后直接从头判断；</li>
</ul>
<p>上面的判断结束后，从<code>feature_buf</code>中pop出一个存到img_msg中，然后遍历imu_buf，讲时间戳小于img_msg的imu数据存到容器IMUs中，然后将IMUs和img_msg作为一个数据对存到measurements中。</p>
<p>2.遍历measurements，对于每个measurement，先遍历所有imu数据，读取imu数据的加速度和角速度，然后调用estimator.processIMU()，将他们作为参数传进processIMU()函数进行操作。<br>这里有一点要注意，往processIMU()传数据时，imu时间戳大于或等于图像时间戳的那个数据要进行一下简单的线性分配。</p>
<pre><code>//对于大多数情况，IMU的时间戳都会比img的早，此时直接选取IMU的数据就行
if (t &lt;= img_t)  //http://wiki.ros.org/sensor_msgs
&#123;   
    if (current_time &lt; 0)
        current_time = t;
    double dt = t - current_time;
    ROS_ASSERT(dt &gt;= 0);
    current_time = t;
    dx = imu_msg-&gt;linear_acceleration.x;
    dy = imu_msg-&gt;linear_acceleration.y;
    dz = imu_msg-&gt;linear_acceleration.z;
    rx = imu_msg-&gt;angular_velocity.x;
    ry = imu_msg-&gt;angular_velocity.y;
    rz = imu_msg-&gt;angular_velocity.z;
    //这里干了2件事，IMU粗略地预积分，然后把值传给一个新建的IntegrationBase对象
    estimator.processIMU(dt, Vector3d(dx, dy, dz), Vector3d(rx, ry, rz));//进行IMU预积分
&#125; 
//对于处于边界位置的IMU数据，是被相邻两帧共享的，而且对前一帧的影响会大一些，在这里，对数据线性分配
else//每个大于图像帧时间戳的第一个imu_msg是被两个图像帧共用的(出现次数少)
&#123;
    double dt_1 = img_t - current_time; //current_time &lt; img_time &lt; t
    double dt_2 = t - img_t;
    current_time = img_t;
    ROS_ASSERT(dt_1 &gt;= 0);
    ROS_ASSERT(dt_2 &gt;= 0);
    ROS_ASSERT(dt_1 + dt_2 &gt; 0);
    //以下操作其实就是简单的线性分配
    double w1 = dt_2 / (dt_1 + dt_2);
    double w2 = dt_1 / (dt_1 + dt_2);
    dx = w1 * dx + w2 * imu_msg-&gt;linear_acceleration.x;
    dy = w1 * dy + w2 * imu_msg-&gt;linear_acceleration.y;
    dz = w1 * dz + w2 * imu_msg-&gt;linear_acceleration.z;
    rx = w1 * rx + w2 * imu_msg-&gt;angular_velocity.x;
    ry = w1 * ry + w2 * imu_msg-&gt;angular_velocity.y;
    rz = w1 * rz + w2 * imu_msg-&gt;angular_velocity.z;
    estimator.processIMU(dt_1, Vector3d(dx, dy, dz), Vector3d(rx, ry, rz));
&#125;
</code></pre><hr>
<h3 id="void-Estimator-processIMU"><a href="#void-Estimator-processIMU" class="headerlink" title="void Estimator::processIMU()"></a>void Estimator::processIMU()</h3><p>首先判断传来的imu是不是整个系统下的第一个imu数据，如果是，则要先给acc_0和gyr_0赋值。然后，判断pre_integrations[frame_count]是否为空，若为空，则new一个,主要操作就是给pre_integrations[frame_count]的成员参数acc_0, gyr_0，linearized_ba, linearized_bg赋值,未初始化时，linearized_ba, linearized_bg的赋值其实都为零。<br>这里的<code>pre_integrations[]</code>就是estimator的成员变量，数组大小为10，就是滑动窗口大小，在estimator的构造函数中，<code>pre_integrations[]</code>中的所有数据都先置为空。<code>pre_integrations[]</code>中的每个数据都是IntegrationBase类型的，这个类型的数据用来存储两帧之间的所有imu数据，预积分值，预积分累计误差的协方差以及残差的jacobian。<br>然后判断frame_count是否为0，若为0则不用进行预积分，直接更新acc_0和gyr_0就结束了，frame_count增加的操作在estimator.processImage()中。<br>若frame_count不为0，则进行预积分，关于预积分的操作从下面这句展开：</p>
<pre><code>pre_integrations[frame_count]-&gt;push_back(dt, linear_acceleration, angular_velocity);
</code></pre><p>这个push_back()是pre_integrations[frame_count]的函数，即IntegrationBase类的成员函数，该函数先把时差，加速度，角速度存到pre_integrations[frame_count]的成员变量dt_buf，acc_buf，gyr_buf中，然后调用函数propagate(dt, acc, gyr)，这个函数也是IntegrationBase类的成员函数，这个函数就放在下面讲了。<br>接下来，把预积分数据也存到tmp_pre_integration中，执行完processIMU()后，下面processImage()函数里，要用tmp_pre_integration给imageframe.pre_integration赋值。</p>
<pre><code>tmp_pre_integration-&gt;push_back(dt, linear_acceleration, angular_velocity);
</code></pre><p>然后就是一些参数存储和更新的工作了：</p>
<pre><code>dt_buf[frame_count].push_back(dt);
linear_acceleration_buf[frame_count].push_back(linear_acceleration);
angular_velocity_buf[frame_count].push_back(angular_velocity);

int j = frame_count;         
Vector3d un_acc_0 = Rs[j] * (acc_0 - Bas[j]) - g;
Vector3d un_gyr = 0.5 * (gyr_0 + angular_velocity) - Bgs[j];
Rs[j] *= Utility::deltaQ(un_gyr * dt).toRotationMatrix();
Vector3d un_acc_1 = Rs[j] * (linear_acceleration - Bas[j]) - g;
Vector3d un_acc = 0.5 * (un_acc_0 + un_acc_1);
Ps[j] += dt * Vs[j] + 0.5 * dt * dt * un_acc;
Vs[j] += dt * un_acc;

acc_0 = linear_acceleration;
gyr_0 = angular_velocity;
</code></pre><hr>
<h3 id="void-propagate"><a href="#void-propagate" class="headerlink" title="void propagate()"></a>void propagate()</h3><p>首先，通过传来的参数，给pre_integrations[frame_count]的成员变量dt, acc_1, gyr_1赋值，再创建一系列变量：</p>
<pre><code>Vector3d result_delta_p;
Quaterniond result_delta_q;
Vector3d result_delta_v;
Vector3d result_linearized_ba;
Vector3d result_linearized_bg;
</code></pre><p>再调用函数</p>
<pre><code>midPointIntegration(_dt, acc_0, gyr_0, _acc_1, _gyr_1, delta_p, delta_q, delta_v,
                        linearized_ba, linearized_bg,
                        result_delta_p, result_delta_q, result_delta_v,
                        result_linearized_ba, result_linearized_bg, 1);
</code></pre><p>这个函数的结果就是保存在上面创建的变量里，下面细看这个函数，midPointIntegration()总体分为两部分，一部分是预积分：</p>
<pre><code>Vector3d un_acc_0 = delta_q * (_acc_0 - linearized_ba);
Vector3d un_gyr = 0.5 * (_gyr_0 + _gyr_1) - linearized_bg;
result_delta_q = delta_q * Quaterniond(1, un_gyr(0) * _dt / 2, un_gyr(1) * _dt / 2, un_gyr(2) * _dt / 2);
Vector3d un_acc_1 = result_delta_q * (_acc_1 - linearized_ba);
Vector3d un_acc = 0.5 * (un_acc_0 + un_acc_1);
result_delta_p = delta_p + delta_v * _dt + 0.5 * un_acc * _dt * _dt;
result_delta_v = delta_v + un_acc * _dt;
result_linearized_ba = linearized_ba;
result_linearized_bg = linearized_bg;
</code></pre><p>这里对应的就是预积分的离散形式，具体公式如下图所示：<img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/VINSMONO/预积分.png" alt="预积分"><br><code>result_delta_q</code>，<code>result_delta_p</code>,<code>result_delta_v</code>,<code>result_linearized_ba</code>,<code>result_linearized_bg</code>就是对应着图中蓝色部分和最后两个，其中<code>result_linearized_ba</code>,<code>result_linearized_bg</code>在未初始化时，都是0。</p>
<p>第二部分是计算累计误差的协方差和残差关于ba、bg的Jacobian。</p>
<pre><code>MatrixXd F = MatrixXd::Zero(15, 15);
F.block&lt;3, 3&gt;(0, 0) = Matrix3d::Identity();
F.block&lt;3, 3&gt;(0, 3) = -0.25 * delta_q.toRotationMatrix() * R_a_0_x * _dt * _dt + 
                        -0.25 * result_delta_q.toRotationMatrix() * R_a_1_x * (Matrix3d::Identity() - R_w_x * _dt) * _dt * _dt;
F.block&lt;3, 3&gt;(0, 6) = MatrixXd::Identity(3,3) * _dt;
F.block&lt;3, 3&gt;(0, 9) = -0.25 * (delta_q.toRotationMatrix() + result_delta_q.toRotationMatrix()) * _dt * _dt;
F.block&lt;3, 3&gt;(0, 12) = -0.25 * result_delta_q.toRotationMatrix() * R_a_1_x * _dt * _dt * -_dt;
F.block&lt;3, 3&gt;(3, 3) = Matrix3d::Identity() - R_w_x * _dt;
F.block&lt;3, 3&gt;(3, 12) = -1.0 * MatrixXd::Identity(3,3) * _dt;
F.block&lt;3, 3&gt;(6, 3) = -0.5 * delta_q.toRotationMatrix() * R_a_0_x * _dt + 
                        -0.5 * result_delta_q.toRotationMatrix() * R_a_1_x * (Matrix3d::Identity() - R_w_x * _dt) * _dt;
F.block&lt;3, 3&gt;(6, 6) = Matrix3d::Identity();
F.block&lt;3, 3&gt;(6, 9) = -0.5 * (delta_q.toRotationMatrix() + result_delta_q.toRotationMatrix()) * _dt;
F.block&lt;3, 3&gt;(6, 12) = -0.5 * result_delta_q.toRotationMatrix() * R_a_1_x * _dt * -_dt;
F.block&lt;3, 3&gt;(9, 9) = Matrix3d::Identity();
F.block&lt;3, 3&gt;(12, 12) = Matrix3d::Identity();
//cout&lt;&lt;&quot;A&quot;&lt;&lt;endl&lt;&lt;A&lt;&lt;endl;

MatrixXd V = MatrixXd::Zero(15,18);
V.block&lt;3, 3&gt;(0, 0) =  0.25 * delta_q.toRotationMatrix() * _dt * _dt;
V.block&lt;3, 3&gt;(0, 3) =  0.25 * -result_delta_q.toRotationMatrix() * R_a_1_x  * _dt * _dt * 0.5 * _dt;
V.block&lt;3, 3&gt;(0, 6) =  0.25 * result_delta_q.toRotationMatrix() * _dt * _dt;
V.block&lt;3, 3&gt;(0, 9) =  V.block&lt;3, 3&gt;(0, 3);
V.block&lt;3, 3&gt;(3, 3) =  0.5 * MatrixXd::Identity(3,3) * _dt;
V.block&lt;3, 3&gt;(3, 9) =  0.5 * MatrixXd::Identity(3,3) * _dt;
V.block&lt;3, 3&gt;(6, 0) =  0.5 * delta_q.toRotationMatrix() * _dt;
V.block&lt;3, 3&gt;(6, 3) =  0.5 * -result_delta_q.toRotationMatrix() * R_a_1_x  * _dt * 0.5 * _dt;
V.block&lt;3, 3&gt;(6, 6) =  0.5 * result_delta_q.toRotationMatrix() * _dt;
V.block&lt;3, 3&gt;(6, 9) =  V.block&lt;3, 3&gt;(6, 3);
V.block&lt;3, 3&gt;(9, 12) = MatrixXd::Identity(3,3) * _dt;
V.block&lt;3, 3&gt;(12, 15) = MatrixXd::Identity(3,3) * _dt;

//step_jacobian = F;
//step_V = V;
jacobian = F * jacobian;
covariance = F * covariance * F.transpose() + V * noise * V.transpose();
</code></pre><p>先简单介绍一下其原理：<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/VINSMONO/协方差1.png" alt="协方差1"><br>把上述公式套到imu的误差传递中，可得到下面这个式子：<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/VINSMONO/协方差5.png" alt="协方差5"><br>这里我们得到了当前imu数据与上一个imu数据误差的线性关系，两帧的协方差可以根据这种线性关系递推得到：<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/VINSMONO/协方差2.png" alt="协方差2"><br>这里的${\sum _i}_{k - 1}$就是上一个imu数据协方差，${\sum _n}$是噪声矩阵，在构造函数中通过从yaml文件中读取的噪声标准差数据赋了值。<br>由上所述，我们现在要求的就是矩阵F,G，结果如下：<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/VINSMONO/协方差3.png" alt="协方差3"><br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/VINSMONO/协方差4.png" alt="协方差4"><br>具体的运算过程太长了，可以去看深蓝学院的ppt，这里的求解内容就存在了代码中的矩阵F和V中，然后用这两个矩阵完成对协方差和雅可比的更新，关于这里的雅可比，目前还不是特别懂，看懂了再回来更新。。。。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/09/04/VINSMONO-NOTE-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/09/04/VINSMONO-NOTE-1/" itemprop="url">VINS-MONO源码阅读:前端</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-09-04T13:04:24+08:00">
                2023-09-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="VINSMONO学习笔记-1"><a href="#VINSMONO学习笔记-1" class="headerlink" title="VINSMONO学习笔记(1)"></a>VINSMONO学习笔记(1)</h1><p>这篇博客开始是对VINSMONO框架的源码学习，最近把深蓝学院的VIO课程看完了，希望通过阅读VINSMONO的源码来进行巩固和加深理解。这篇博客主要是对VINSMONO的整体框架的梳理和对前端节点代码的阅读。</p>
<p>参考博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/mcw1234/article/details/83039506">VINS-Mono详解（一）</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/wbzhang233/article/details/88885485">港科大VINS-MONO入门（一）：框架入门及源码解析</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_51547017/article/details/123306540">VINS_mono 代码详细理解（一）</a></p>
<hr>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p>VINS-Mono是基于ros开发的，主要包含两个节点: 前端节点<code>feature_tracker_node</code>和后端节点<code>estimator_node</code>。前端节点处理Measurement Preprocessing中的Feature Detection and Tracking, 其他几个部分(IMU preintegration, initialization, LocalBA, Loop closure)都是在estimator_node中处理。 </p>
<p>前端节点的feature_tracker_node的程序入口是文件feature_tracker_node.cpp中的main()函数，接收图像信息,调用img_callback()函数进行处理。</p>
<p>estimator_node节点中开了3个子线程, 分别是:process,loop_detection和pose_graph. 其中 process()线程处理VIO后端, 包括(IMU preintegration, initialization, LocalBA)loop_detection()线程处理闭环检测pose_graph()线程分别处理全局优化。如果不需要做loop closure, 可以把LOOP_CLOUSRE置0, 则后面两个线程不会创建。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="int-main"><a href="#int-main" class="headerlink" title="int main()"></a>int main()</h3><p>首先，读取yaml文件中的相关参数，再创建由FeatureTracker类的实例组成的数组<code>trackerData[NUM_OF_CAM]</code>，其中<code>NUM_OF_CAM</code>为相机的个数，这意味这每一个相机都有一个FeatureTracker的实例，每个相机的FeatureTracker实例通过调用成员函数FeatureTracker::readIntrinsicParameter()，来读取每个相机各自对应的内参。</p>
<p>特别的，如果相机是鱼眼相机，需要读取FISHEYE_MASK，存到相机FeatureTracker的实例的成员变量fisheye_mask中，它会在后续操作中被用来去除边缘噪点。</p>
<p>接着定义一个订阅器和两个发布器。订阅器sub_img从话题IMAGE_TOPIC中订阅相机图像数据，回调函数为img_callback()。发布器pub_img在名为feature的话题下发布一条类型为sensor_msgs::PointCloud的消息，该话题消息为从相机图像中跟踪的特征点。发布器pub_match在名为feature_img的话题下发布一条类型为sensor_msgs::Image的消息，该话题消息为标记出了特征点的图像。<br>| |name|topic|type|消息内容|<br>|-|:———-:|:———:|:———:|:———:|<br>|subscriber|sub_img|IMAGE_TOPIC|sensor_msgs::Image|相机图像数据|<br>|publisher|pub_img|feature|sensor_msgs::PointCloud|跟踪的特征点|<br>|publisher|pub_match|feature_img|sensor_msgs::Image|标记出了特征点的图像|</p>
<hr>
<h3 id="void-img-callback"><a href="#void-img-callback" class="headerlink" title="void img_callback()"></a>void img_callback()</h3><p>每当接收到从IMAGE_TOPIC话题订阅的数据，就会进入回调函数img_callback()进行处理。对于传来的图像，首先要判断其是否需要发送，并不是每处理一帧图像，都将特征点检测跟踪结果发布出去。数据发布频率由配置参数FREQ给定，通过PUB_THIS_FRAME控制是否发布当前帧的检测跟踪数据，将数据平均发布频率稳定在FREQ：如果当前统计时间内的平均数据发布频率快于FREQ，则将PUB_THIS_FRAME置为false，只进行特征点的跟踪，但不发布当前帧的数据；否则，将PUB_THIS_FRAME置为true，进行特征点的跟踪且发布当前帧的数据。</p>
<p>然后遍历成员变量<code>trackerData</code>数组，调用该对象的函数readImage()，将数据读取存储到<code>trackerData</code>里(这部分下面会详细讲)。然后更新<code>trackerData</code>里特征点的id。</p>
<p>接下来，创建了一个名为 <code>feature_points</code> 的指针，该指针指向一个 sensor_msgs::PointCloud 类型的消息对象,将<strong>当前帧的所有特征点在归一化平面上的坐标</strong>存到<code>feature_points</code>的成员变量<code>points</code>中，将<strong>当前帧的所有特征点的像素坐标，id，xy轴方向的速度</strong>存到<code>feature_points</code>的成员变量<code>channels</code>中，通过<code>pub_img</code>发布出去（第一帧不发送）。</p>
<p>最后，如果要进行特征点轨迹的可视化，即SHOW_TRACK为true，则将原来转为灰度图的图像重新恢复成彩色图，存到变量stereo_img里，然后按图像大小截取到tmp_img里，在tmp_img中特征点坐标处画圆圈，颜色深度由追踪到的次数决定，通过<code>pub_match</code>将处理过的图像发布出去。</p>
<hr>
<h3 id="void-FeatureTracker-readImage"><a href="#void-FeatureTracker-readImage" class="headerlink" title="void FeatureTracker::readImage()"></a>void FeatureTracker::readImage()</h3><p>FeatureTracker类中的主要处理函数就是readImage()，在这个函数中涉及到几个变量名，需要对它们的含义进行特别说明（以下说明针对单目模式，其含义并不适用于双目模式），否则根据变量名称去揣测其含义会出错。</p>
<p>图像数据变量：</p>
<p><code>prev_img</code>： 上一次发布数据时对应的图像帧<br><code>cur_img</code>： 光流跟踪的前一帧图像，而不是“当前帧”<br><code>forw_img</code>： 光流跟踪的后一帧图像，真正意义上的“当前帧”特征点数据变量：</p>
<p><code>prev_pts</code>： 上一次发布的，且能够被当前帧（forw）跟踪到的特征点<br><code>cur_pts</code>： 在光流跟踪的前一帧图像中，能够被当前帧（forw）跟踪到的特征点<br><code>forw_pts</code>： 光流跟踪的后一帧图像，即当前帧中的特征点（除了跟踪到的特征点，可能还包含新检测的特征点）</p>
<p>函数的具体流程为：<br>1.如果控制参数EQUALIZE为true，调用cv::createCLAHE对图像进行自适应直方图均衡处理；</p>
<p>2.调用cv::calcOpticalFlowPyrLK()对前一帧的特征点cur_pts进行金字塔光流跟踪，得到forw_pts。status标记了cur_pts中各个特征点的跟踪状态，根据status将跟踪失败的特征点从prev_pts、cur_pts和forw_pts中剔除，而且在记录特征点id的ids，和记录特征点被跟踪次数的track_cnt中，也要把这些跟踪失败的特征点对应位置的记录删除。被status标记为跟踪正常的特征点，在当前帧图像中的位置可能已经处于图像边界外了，这些特征点也应该被删除，删除操作同上。最后将未被删除的点的跟踪次数加1。</p>
<p>3.如果不需要发布当前帧的数据，则直接将当前帧forw的相关数据赋给上一帧cur，然后在这一步整个readImage的流程就结束了。</p>
<p>4.如果需要发布当前帧的数据，先调用FeatureTracker::rejectWithF()函数，剔除outliers。具体方法为：调用cv::findFundamentalMat()对prev_pts和forw_pts计算F矩阵，通过F矩阵去除outliers。剩下的特征点track_cnt都加一。</p>
<p>5.调用FeatureTracker::setMask()，通过设置一个mask，使跟踪的特征点在整幅图像中能够均匀分布，防止特征点扎堆。FeatureTracker::setMask()的具体操作为：对光流跟踪到的特征点forw_pts，按照被跟踪到的次数降序排列，然后按照降序遍历这些特征点。每选中一个特征点，在mask中将该点周围半径为MIN_DIST的区域设置为30，后面不再选取该区域内的特征点。这样会删去一些特征点，使得特征点分布得更加均匀，同时尽可能地保留被跟踪次数更多的特征点。</p>
<p>6.由于光流跟踪到的特征点会减少，而且setMask()的处理过程中也会删除一些特征点，所以需要新检测一些特征点（只有需要发布数据时，才会检测新的特征点，否则只跟踪，不检测新的特征点）。具体操作为：调用cv::goodFeaturesToTrack()在mask中不为0的区域检测新的特征点，将特征点数量补充至指定数量。然后调用FeatureTracker::addPoints()，将新检测到的特征点到forw_pts中去，id初始化为-1，track_cnt初始化为1。</p>
<p>7.将cur的相关变量赋给prev的相关变量，forw的相关变量赋给cur的相关变量，调用函数undistortedPoints()，对当前帧的特征点去畸变，得到<code>cur_un_pts</code> 、<code>cur_un_pts_map</code> 、<code>prev_un_pts_map</code> ,并且求出每个特征点xy方向的速度。undistortedPoints()中调用了liftProjective()函数实现了去畸变，它用的方法和slam14讲里面的不太一样，它使用迭代畸变模型，循环迭代八次，这样效果比函数近视好，而速度也比opencv的API快。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/27/ORBSLAM3-NOTE-12/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/04/27/ORBSLAM3-NOTE-12/" itemprop="url">ORB-SLAM3源码阅读:KeyFrameDatabase</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-04-27T15:31:18+08:00">
                2023-04-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-12"><a href="#ORBSLAM3学习笔记-12" class="headerlink" title="ORBSLAM3学习笔记(12)"></a>ORBSLAM3学习笔记(12)</h1><p>这篇博客主要是对KeyFrameDatabase.cc文件的学习，这部分的内容很少，原来不打算专门写一篇的，但写在别的地方又太乱了，还是在这里记录一下吧。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="KeyFrameDatabase-DetectRelocalizationCandidates"><a href="#KeyFrameDatabase-DetectRelocalizationCandidates" class="headerlink" title="KeyFrameDatabase::DetectRelocalizationCandidates()"></a>KeyFrameDatabase::DetectRelocalizationCandidates()</h3><ol>
<li>找出和当前帧具有公共单词的所有关键帧<blockquote>
<p>这里是通过遍历成员变量mvInvertedFile得到的，mvInvertedFile就是存储每个单词所有的关键帧的。把关键帧添加到mvInvertedFile的步骤是在闭环线程进行的。</p>
</blockquote>
</li>
<li>统计上述关键帧中与当前帧F具有共同单词最多的单词数，用来设定阈值1<blockquote>
<p>阈值1是最小公共单词数为最大公共单词数目的0.8倍</p>
</blockquote>
</li>
<li>遍历上述关键帧，挑选出共有单词数大于阈值1的及其和当前帧单词匹配得分存入lScoreAndMatch<blockquote>
<p>这里的得分是通过DBoW2库的score()函数计算得来的，用mBowVec来计算两帧的相似度得分，具体代码就先不看了。</p>
</blockquote>
</li>
<li>计算lScoreAndMatch中每个关键帧的共视关键帧组的总得分，得到最高组得分bestAccScore，并以此决定阈值2<blockquote>
<p>注意，这里将与关键帧共视程度最高的前十个关键帧归为一组，计算累计得分。阈值2是最高得分组的0.75倍</p>
</blockquote>
</li>
<li>得到所有组中总得分大于阈值2的，组内得分最高的关键帧，作为候选关键帧组。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/13/ORBSLAM3-NOTE-11/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/04/13/ORBSLAM3-NOTE-11/" itemprop="url">ORB-SLAM3源码阅读:MapPoint</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-04-13T19:29:38+08:00">
                2023-04-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-11"><a href="#ORBSLAM3学习笔记-11" class="headerlink" title="ORBSLAM3学习笔记(11)"></a>ORBSLAM3学习笔记(11)</h1><p>这篇博客主要是对MapPoint.cc文件的学习。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="MapPoint-AddObservation"><a href="#MapPoint-AddObservation" class="headerlink" title="MapPoint::AddObservation()"></a>MapPoint::AddObservation()</h3><p>这个函数引用的参数为(KeyFrame* pKF, int idx),及关键帧与特征点索引值，功能是为MapPoint的成员变量mObservations赋值，所以我们先详细看一下这个变量就行。<br>首先，它的类型为std::map<KeyFrame\*,std::tuple<int,int>&gt; 这是一个map容器，键值为我们传过来的KeyFrame，value是一个元组类型std::tuple&lt; int,int&gt;，由于我们看的是单目，其实我们只用得到元组的第一个位置，存储的是该MapPoint在该关键帧的投影特征点的索引值。<br>最后还要更新成员int nObs，该成员记录了当前地图点被多少个关键帧相机观测到了(单目关键帧每次观测算1个相机,双目/RGBD帧每次观测算2个相机)。</p>
<hr>
<h3 id="MapPoint-UpdateNormalAndDepth"><a href="#MapPoint-UpdateNormalAndDepth" class="headerlink" title="MapPoint::UpdateNormalAndDepth()"></a>MapPoint::UpdateNormalAndDepth()</h3><p>该函数的功能是更新地图点平均观测方向和观测距离范围。首先看一下观测距离范围是什么意思，这部分就参考博客<a target="_blank" rel="noopener" href="https://blog.csdn.net/ncepu_Chen/article/details/116784652?spm=1001.2014.3001.5502">ORB-SLAM2代码详解03: 地图点MapPoint</a>，然后在看具体代码。</p>
<p><strong>基本概念</strong><br>MapPoint类中观测距离范围的由成员变量mfMaxDistance和mfMinDistance表示。</p>
<ul>
<li><code>mfMaxDistance</code>表示若地图点匹配在某特征提取器图像金字塔第7层上的某特征点,观测距离值</li>
<li><code>mfMinDistance</code>表示若地图点匹配在某特征提取器图像金字塔第0层上的某特征点,观测距离值<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/观测尺度1.png" alt="观测尺度"><br>这里的dist是由参考关键帧得到的，参考关键帧就是创建MapPoint对象时传递过去的KeyFrame参数。dist与mfMaxDistance，mfMinDistance之间的换算关系为\[\frac{mfMaxDistance}{dist}\text={1.2^{level}},\frac{dist}{mfMinDistance}\text={1.2^{(n-1-\text{level})}}\]<script type="math/tex">level</script>是MapPoint在参考关键帧中对应关键点的金字塔层数，$n$是金字塔的总层数。</li>
</ul>
<p><strong>平均观测方向</strong><br>遍历每个观测到该地图点的关键帧，求他们光心到该地图点的向量，即观测方向，光心就是该关键帧的位姿变换的平移部分。然后将该向量归一化，将所有向量加起来除以向量个数。</p>
<p><strong>观测距离范围</strong><br>得到参考关键帧(即地图点第一次创建时的关键帧)与地图点之间的距离</p>
<pre><code>Eigen::Vector3f PC = Pos - pRefKF-&gt;GetCameraCenter(); 
const float dist = PC.norm(); 
</code></pre><p>然后根据上面的公式求得最大距离和最小距离。</p>
<p>最后，该函数就是把平均观测方向存入mNormalVector中，把最大和最小距离存入mfMaxDistance和mfMinDistance中。</p>
<p><strong>函数MapPoint::UpdateNormalAndDepth()的调用时机:</strong></p>
<ul>
<li>创建地图点时调用该函数初始化其观测信息。</li>
<li>地图点对关键帧的观测<code>mObservations</code>更新时(<strong>跟踪局部地图添加或删除对关键帧的观测</strong>时、<strong>LocalMapping线程删除冗余关键帧</strong>时或<strong>LoopClosing线程闭环矫正</strong>时),调用该函数初始化其观测信息。</li>
<li>地图点世界坐标mWorldPos发生变化时(BA优化之后),调用该函数初始化其观测信息.</li>
</ul>
<p>总结成一句话: 只要地图点本身或关键帧对该地图点的观测发生变化,就应该调用该函数更新其观测尺度和方向信息。</p>
<hr>
<h3 id="MapPoint-Replace"><a href="#MapPoint-Replace" class="headerlink" title="MapPoint::Replace()"></a>MapPoint::Replace()</h3><p>函数的调用形式为pMPinKF-&gt;Replace(pMP)。将pMPinKF地图点替换成pMP。下面看具体步骤：</p>
<ol>
<li>先将mMutexFeatures，mMutexPos上锁(这里是避免track线程里获取mpReplaced时冲突)，将pMP赋值给mpReplaced;</li>
<li>我们先把pMPinKF的<code>mObservations</code>拷贝到obs，再将<code>mObservations</code>清空。</li>
<li>遍历obs，每次拿出一组关键帧pKF和对应索引值indexes，判断传过来的pMP是否在pKF中：</li>
</ol>
<ul>
<li>若不在，把pMP存到pKF的<code>mvpMapPoints</code>的indexes的位置，这里本来存储的是pMPinKF，这一步就是用pMP把pMPinKF覆盖了。再把pKF添加到pMP的<code>mObservations</code>中。</li>
<li>若存在，我们直接把pKF中的pMPinKF删掉就行。</li>
</ul>
<ol>
<li>将当前地图点的观测数据等其他数据都”叠加”到新的地图点上，包括nfound，nvisible，更新地图点描述子，删掉地图中的pMPinKF。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/13/ORBSLAM3-NOTE-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/04/13/ORBSLAM3-NOTE-10/" itemprop="url">ORB-SLAM3源码阅读:KeyFrame</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-04-13T19:26:34+08:00">
                2023-04-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-10"><a href="#ORBSLAM3学习笔记-10" class="headerlink" title="ORBSLAM3学习笔记(10)"></a>ORBSLAM3学习笔记(10)</h1><p>这篇博客主要是对KeyFrame.cc文件的学习。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="KeyFrame-KeyFrame"><a href="#KeyFrame-KeyFrame" class="headerlink" title="KeyFrame::KeyFrame()"></a>KeyFrame::KeyFrame()</h3><p>就是通过传来的参数给相应的成员变量赋值。传来的pMap对象是指针型的，故KeyFrame类对象的成员变量mpMap指向的是Atlas类对象的成员变量mpCurrentMap。</p>
<hr>
<h3 id="KeyFrame-ComputeBoW"><a href="#KeyFrame-ComputeBoW" class="headerlink" title="KeyFrame::ComputeBoW()"></a>KeyFrame::ComputeBoW()</h3><p>这里就是给mBowVec和mFeatVec两个成员变量赋值。这里可以直接看<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41694024/article/details/126328833">ORB-SLAM2 —— Frame::ComputeBoW函数</a>,这篇博客讲得细致清晰，我就不多做赘述了，就直接放下源码注释。</p>
<pre><code>void KeyFrame::ComputeBoW()
&#123;
    // 只有当词袋向量或者节点和特征序号的特征向量为空的时候执行
    if (mBowVec.empty() || mFeatVec.empty())
    &#123;
        // 将描述子mDescriptors转换为DBOW要求的输入格式
        vector&lt;cv::Mat&gt; vCurrentDesc = Converter::toDescriptorVector(mDescriptors);

        // 将特征点的描述子转换成词袋向量mBowVec以及特征向量mFeatVec
        mpORBvocabulary-&gt;transform(vCurrentDesc,    //当前的描述子vector
                               mBowVec,         //输出，词袋向量，记录的是单词的id及其对应权重TF-IDF值
                               mFeatVec,        //输出，记录node id及其对应的图像 feature对应的索引
                               4);              //4表示从叶节点向前数的层数
    &#125;
&#125;
</code></pre><p>关于mBowVec和mFeatVec的具体类型，看以下注释。</p>
<pre><code>// Bag of Words Vector structures.
// 内部实际存储的是std::map&lt;WordId, WordValue&gt;
// WordId 和 WordValue 表示Word在叶子中的id 和权重
DBoW2::BowVector mBowVec;
// 内部实际存储 std::map&lt;NodeId, std::vector&lt;unsigned int&gt; &gt;
// NodeId 表示节点id，std::vector&lt;unsigned int&gt; 中实际存的是该节点id下所有特征点在图像中的索引
DBoW2::FeatureVector mFeatVec;
</code></pre><hr>
<h3 id="KeyFrame-UpdateConnections"><a href="#KeyFrame-UpdateConnections" class="headerlink" title="KeyFrame::UpdateConnections()"></a>KeyFrame::UpdateConnections()</h3><p>1.创建map<KeyFrame *, int>类变量KFcounter，键是该关键帧的共视关键帧，值是该这两个关键帧的共视点数目。</p>
<blockquote>
<p>具体做法是先获得该关键帧的所有地图点。遍历地图点，根据地图点的成员变量mObservations，往KFcounter中添加键值对。</p>
</blockquote>
<p>2.创建vector<pair<int, KeyFrame *>&gt;类变量vPairs，这里面存储与该关键帧共视点超过15的关键帧。</p>
<blockquote>
<p>这步就是遍历KFcounter，把达到要求的共视关键帧以及共视点数目放入vPairs中。同时调用AddConnection(),给这个共视关键帧更新连接及权重。<br>AddConnection()就是为std::map<KeyFrame*,int>类成员变量<code>mConnectedKeyFrameWeights</code>赋值，之后调用UpdateBestCovisibles()，对连接关系按照权重(即共视点数目)从大到小排序，把排完序的关键帧和权重存入<code>mvpOrderedConnectedKeyFrames</code>和<code>mvOrderedWeights</code>中。</p>
</blockquote>
<p>3 如果没有连接到关键帧（超过阈值的权重），则对权重最大的关键帧建立连接，同时调用AddConnection(),给这个权重最大的关键帧更新连接及权重。<br>4.对共视程度比较高的关键帧对更新连接关系及权重</p>
<blockquote>
<p>前面我们已经把共视程度比较高的关键帧存入vPairs中了，也为这些关键帧更新了连接关系及权重，但我们自己还没更新。这步就是给自己更新的，操作和上面差不多，排好序后，存入成员变量<code>mvpOrderedConnectedKeyFrames</code>和<code>mvOrderedWeights</code>中。</p>
</blockquote>
<p>5.更新生成树的连接</p>
<blockquote>
<p>将该关键帧的成员变量<code>mpParent</code>指向共视程度最高的那个关键帧，得到了该关键帧的父关键帧。<br>mpParent调用函数AddChild(),在这个父关键帧的成员变量<code>mspChildrens</code>容器中添加了一个关键帧，即我们目前的关键帧，表明这个关键帧是父关键帧的子关键帧。</p>
</blockquote>
<p><strong>总结</strong><br>该函数为调用该函数的关键帧的成员变量<code>mvpOrderedConnectedKeyFrames</code>和<code>mvOrderedWeights</code>赋值，里面保存了共视程度比较高的关键帧和权重。同时，也在这些共视程度比较高的关键帧的<code>mvpOrderedConnectedKeyFrames</code>和<code>mvOrderedWeights</code>中添加了该关键帧和对应权重。<br>最后，将<code>mpParent</code>指向共视程度最高的那个关键帧，也在那个共视程度最高的那个关键帧的<code>mspChildrens</code>中添加了该关键帧。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/11/ORBSLAM3-NOTE-9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/04/11/ORBSLAM3-NOTE-9/" itemprop="url">ORB-SLAM3源码阅读:TwoViewReconstruction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-04-11T13:53:20+08:00">
                2023-04-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-9"><a href="#ORBSLAM3学习笔记-9" class="headerlink" title="ORBSLAM3学习笔记(9)"></a>ORBSLAM3学习笔记(9)</h1><p>这篇博客主要是对TwoViewReconstruction.cc文件的学习。</p>
<hr>
<h2 id="一、基本原理"><a href="#一、基本原理" class="headerlink" title="一、基本原理"></a>一、基本原理</h2><p>这个文件用来完成单目初始化，里面涉及特征点坐标的归一化，对极约束求基础矩阵，求单应矩阵，RANSAC方法，双向重投影误差</p>
<hr>
<h3 id="1-特征点归一化"><a href="#1-特征点归一化" class="headerlink" title="1.特征点归一化"></a>1.特征点归一化</h3><p>矩阵A是利用8点法求基础矩阵的关键,所以Hartey就认为,利用8点法求基础矩阵不稳定的一个主要原因就是原始的图像像点坐标组成的系数矩阵A不好造成的,而造成A不好的原因是像点的齐次坐标各个分量的数量级相差太大。基于这个原因,Hartey提出一种改进的8点法,在应用8点法求基础矩阵之前,先对像点坐标进行归一化处理,即对原始的图像坐标做同向性变换,这样就可以减少噪声的干扰,大大的提高8点法的精度。</p>
<p>预先对图像坐标进行归一化有以下好处：<br>1.能够提高运算结果的精度。<br>2.利用归一化处理后的图像坐标,对任何尺度缩放和原点的选择是不变的。归一化步骤预先为图像坐标选择了一个标准的坐标系中,消除了坐标变换对结果的影响。</p>
<p>坐标归一化主要分为平移和缩放，具体步骤如下：<br><strong>平移</strong><br>首先求均值</p>
<script type="math/tex; mode=display">\begin{cases} x_{mean}=\frac{1}{N}\sum_{i}^{N}{p_x^i}\\ y_{mean}=\frac{1}{N}\sum_{i}^{N}{p_y^i} \end{cases}</script><p>得到均值后，用原坐标减去均值，这里的均值相当于新的坐标原点</p>
<script type="math/tex; mode=display">p_x^i=p_x^i-x_{mean},p_y^i=p_y^i-y_{mean}</script><p><strong>缩放</strong><br>首先求系数\$s_x\$和\$s_y$，系数的几何意义就是单位距离。求法就是所有坐标到新原点$(x_{mean},y_{mean})$的距离之和的均值。<br>$\begin{cases} s_x = \frac{\sum\limits_{i = 0}^N {|p_x^i - x_{mean}|}}N\\s_y = \frac{\sum\limits_{i = 0}^N {|p_y^i - y_{mean}|} }N\end{cases}$<br>得到系数后，将平移后的坐标乘以单位距离，就得到归一化的坐标了。<br>$p_x^i=s_xp_x^i,p_y^i=s_yp_y^i$</p>
<p>这两个过程可以用一个变换T来描述</p>
<script type="math/tex; mode=display">p' = TpT=\left[ \begin{matrix}
   s_x & 0 & -{x_{mean}}s_x  \\
   0 & s_y & -{y_{mean}}s_y  \\
   0 & 0 & 1  \\
\end{matrix} \right]</script><p>这个T要保存一下，等会计算出来H、F，是归一化后的，以H为例，要用$T^{-1}HT$还原回来。</p>
<hr>
<h3 id="2-基础矩阵求解"><a href="#2-基础矩阵求解" class="headerlink" title="2.基础矩阵求解"></a>2.基础矩阵求解</h3><p>这一部分十四讲讲得还是比较细致的，图我就不放了，就直接进行一下运算推导吧<br>已知$p_1,p_2$是路标点$P$的像素坐标，得到$s_1p_1=KP,s_2p_2=K(RP+t)$,这里的$s_1,s_2$就是路标点的深度信息。现在取$x_1=K^{-1}p_1,x_2=K^{-1}p_2$显然，$x_1,x_2$是两个像素点的归一化平面上的坐标。这里我们不用尺度意义相等，直接代入上式，得\[s_2x_2=s_1R{x_1}+t\]然后两边同时与t做外积\[s_2t\hat{\ }x_2=s_1t\hat{\ }R{x_1}\]然后，两侧同时左乘$x_2^T$,由于左边的向量垂直于$x_2$，两个垂直向量的内积为0，故得到\[\frac{s_1}{s_2}x_2^Tt\hat{\ }Rx_1=0\]由这个式子可以看出，$s_1,s_2$无论取什么值都是没有意义的，取什么式子都成立，故路标点的深度信息缺失了，上式有尺度不确定性。<br>我们把$s_1,s_2$约掉，重新代入$p_1,p_2$得\[p_2^TK^{-1}t\hat{\ }RK^{-1}p_1=0 \]令$E=t\hat{\ }R,F=K^{-T}EK^{-1}$,E就是本质矩阵，F就是基础矩阵，下面求解基础矩阵。<br>展开成矩阵形式<script type="math/tex">\left( u_2,v_2,1 \right)\left( \begin{matrix}
   f_1 & f_2 & f_3  \\
   f_4 & f_5 & f_6  \\
   f_7 & f_8 & f_9  \\
\end{matrix} \right)\left( \begin{matrix}
   u_1  \\
   v_1  \\
   1  \\
\end{matrix} \right)=0</script>整理成$Ax=0$的形式:\[\left[ u_2u_1,u_2v_1,u_2v_2,u_1,v_2v_1,v_2,u_1,v_1,1 \right]f=0\]这里一个点对形成一个约束，$f$有9个变量，但$t\hat{\ }R$实际上只有6个自由度，再加上缺少深度信息，有尺度不确定性，其实只有5自由度。我们选择8个点对，求解出$f$的参数。<br>基础矩阵F可以做奇异值分解得\[F=UΣV^T\]我们需要根据$U,Σ,V$来求$R,t$,且$Σ=diag(σ,σ,0)$,这是本质矩阵的基本性质，但我们根据线性方程解出来的$F$很可能不满足该性质，因此一般都是$F$矩阵进行奇异值分解，强制令最小奇异值为0，然后重构回来得到$F$。<br>最后，关于我们求得的$R,t$尺度不确定性的问题，由于旋转矩阵$R$有其自身的约束，我们就认为这份不确定性在t上，为了解决这个问题，我们把t归一化，让它长度为一。这样，我们就把尺度定好了，接下来，我们就能用这个单位长度为1的t来求路标点深度，接下来的t也都以此为参考，这样我们初始化的目标就达到了。</p>
<hr>
<h3 id="3-单应矩阵求解"><a href="#3-单应矩阵求解" class="headerlink" title="3.单应矩阵求解"></a>3.单应矩阵求解</h3><p>单应矩阵的推导十四讲里写得很简略，我们这里先看图<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/%E5%8D%95%E5%BA%94%E7%9F%A9%E9%98%B5.png" alt="示例图"><br>上图表示场景中的平面$π$在两相机的成像，P是平面上的路标点(图片中是X)，设平面$π$在第一个相机坐标系下的单位法向量为$n$，平面到第一个相机中心（坐标原点）的距离为d，则平面$π$满足方程：\[n^TP=d\]这个式子还是好理解的，就是光心到P点的向量点乘法向量，就是$P$在法向量的投影长度乘以法向量单位长度1，很明显就是对于d。将上式变换为\[\frac1dn^TP=1\]把上式代入$p_2≃K(RP+t)$中，得到\[p_2≃K\left( RP+t\left( \frac{n^TP}d \right) \right)≃K\left( R-\frac{tn^T}d \right)P≃K\left( R-\frac{tn^T}d \right)K^{-1}p_1\]中间部分记为H，则\[p_2≃Hp_1\]将该式矩阵展开\[\left[ \begin{matrix}<br>   u_2  \\<br>   v_2  \\<br>   1  \\<br>\end{matrix} \right]≃\left[ \begin{matrix}<br>   h_1 &amp; h_2 &amp; h_3  \\<br>   h_4 &amp; h_5 &amp; h_6  \\<br>   h_7 &amp; h_8 &amp; h_9  \\<br>\end{matrix} \right]\left[ \begin{matrix}<br>   u_1  \\<br>   v_1  \\<br>   1  \\<br>\end{matrix} \right]\]分开写\[u_2=\frac{h_1u_1+h_2v_1+h_3}{h_7u_1+h_8v_1+h_9}\]\[v_2=\frac{h_4u_1+h_5v_1+h_6}{h_7u_1+h_8v_1+h_9}\]<br>整理成$Ax=0$的形式<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/6.png" alt="公式"><br>根据上面的式子可以看出一对匹配点可以构造两个约束，其实我们用四对点就能解了，但还是和上面保持一致，用8组点。对于最小二乘法问题$Ax=0$，有很多解法，orbslam3直接进行SVD分解，最小奇异值对应的奇异向量就是x的解。</p>
<hr>
<h3 id="4-RANSAC方法"><a href="#4-RANSAC方法" class="headerlink" title="4.RANSAC方法"></a>4.RANSAC方法</h3><p>RANSAC就是随机采样一致，简单理解为随机取一小部分样本计算模型，然后统计在该模型下的内点数（inliers），重复很多次，取内点数最多的那次的模型为最优结果。随机抽取一部分样本计算模型，而不是用整个样本计算，是因为样本中存在outliers，一起计算会影响结果。ransac寄希望于取的那小部分样本全都是优秀的inliers，这样算出来的模型就会是很好的，所以要重复很多次。<br>orbslam3用的是简化过的RANSAC方法，它就是每次去8个不同的点，计算H或F，然后用这个H或F对所有匹配点计算双向重投影误差，利用卡方检验，评判H或F好坏。重复若干次，取其中最好的H或F。<br>下面讲一下通常的RANSAC方法<br>1.随机的从S中选择s个数据点组成一个样本做为模型的一个示例。其中s是构建模型需要最少的点，如拟合直线s=2。<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/RANSAC1.png" alt="RANSAC1"><br>2.计算S中所有点与模型的距离，确定在模型距离阈值t内的数据点集Si，Si称为采样的一致集并定义为S的内点。<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/RANSAC2.png" alt="RANSAC2"><br>3.如果Si的大小（内点的数目）大于某个阈值T，用Si的所有点重新估计模型并结束。<br>4.如果Si的大小小于T，选择一个新的子集并重复1，2，3的过程。<br>5.经过N次试验选择最大一致集Si，并用Si所有点重新估计模型。<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/RANSAC3.png" alt="RANSAC2"></p>
<hr>
<h3 id="5-卡方检验"><a href="#5-卡方检验" class="headerlink" title="5.卡方检验"></a>5.卡方检验</h3><p>RANSAC迭代过程中，由于可能使用的点是外点，结果会有很大误差，我们要剔除这些结果，只留下最好的H或F。因此我们要去评估求得的结果的误差大小，而卡方检验正好满足我们的需求。<br>卡方检验我们需要了解三个东西卡方值，自由度，卡方检验表。首先是卡方值，我们先计算重投影误差，这也就是残差，而残差的平方除以随机项方差服从卡方分布，这是因为残差平方和中每一项都服从N（0,1）也就是标准正态分布，故他们之和服从卡方分布，这是卡方分布的基本定义。由此我们可以得出该问题的卡方值就是残差的平方除以随机项方差。然后根据自由度，查卡方检验表，得到阈值。比较卡方值和阈值，超出的我们就舍弃，在范围内的，我们就代入公式计算得分。<br>对于H\[p_2=H_{21}p_1,p_1=H_{12}p_2\]将$p_1$通过$H_{21}$投影得到$p_2’$，同理将 $p_2$通过$H_{12}$投影得到$p_1’$，卡方值就是$\frac{||p_1-p_1’||^2_2}{\sigma ^2}$和$\frac{||p_2-p_2’||^2_2}{\sigma ^2}$，其中$\sigma=1$,该模型下的自由度为2，因为计算的是坐标(u,v)的残差。取95%置信度下的自由度为2的卡方检验统计量阈值等于5.991。然后比较卡方值和阈值，若超过，则内点标志位置为false，反之，则用阈值减去卡方值，算入得分中。<br>对于F，残差其实是投影点到极线的距离。$Fp_1$得到的三个值a,b,c,很明显，$p_2$就在直线ax+by+c=0上，但由于误差存在，$p_2$位置肯定会有所偏移，由此计算点到线的距离为残差。这里的自由度为1(z这里没太搞懂)，取95%置信度下的自由度为1的卡方检验统计量阈值,然后和上面步骤差不多。</p>
<hr>
<h3 id="6-由F恢复R-t"><a href="#6-由F恢复R-t" class="headerlink" title="6.由F恢复R,t"></a>6.由F恢复R,t</h3><hr>
<h3 id="7-由H恢复R-t"><a href="#7-由H恢复R-t" class="headerlink" title="7.由H恢复R,t"></a>7.由H恢复R,t</h3><hr>
<h3 id="8-三角化恢复3D坐标"><a href="#8-三角化恢复3D坐标" class="headerlink" title="8.三角化恢复3D坐标"></a>8.三角化恢复3D坐标</h3><p>一个3D点的齐次坐标为${\left[ x,y,z,1 \right]}^{T}$，它到图像上的投影为\[\lambda \left[ \begin{matrix}<br>   u  \\<br>   v  \\<br>   1  \\<br>\end{matrix} \right]=\underbrace{K\left[ R|t \right]}_{P}\left[ \begin{matrix}<br>   x  \\<br>   y  \\<br>   z  \\<br>   1  \\<br>\end{matrix} \right]\]\[\Downarrow \]\[\lambda \textbf{u}=\textbf{PX}\]两边同时左叉乘$\textbf{u}$,有\[\textbf{u}\hat{\ }\textbf{PX}=0\]展开后可得\[\left[ \begin{matrix}<br>   0 &amp; -1 &amp; v  \\<br>   1 &amp; 0 &amp; -u  \\<br>   -v &amp; u &amp; 0  \\<br>\end{matrix} \right]\left[ \begin{matrix}<br>   P_1  \\<br>   P_2  \\<br>   P_3  \\<br>\end{matrix} \right]X=0\]\[\Downarrow \]\[\left\{ \begin{matrix}<br>   (v{P_3}-{P_2})X=0  \\<br>   ({P_1}-u{P_3})X=0  \\<br>   (u{P_2}-v{P_1})X=0  \\<br>\end{matrix} \right.\]上面的方程很明显是线性相关的，实际上只有两个约束，但我们这里有两帧上的匹配点，由此可以得到两组方程即四个约束：<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/三角化.png" alt="三角化"><br>这里可以使用SVD求解，齐次坐标$\textbf{X}$即为$\textbf{H}$的最小奇异值的奇异向量。<br>这部分的代码实现在GeometricTools::Triangulate()函数中。</p>
<hr>
<h2 id="二、源码阅读"><a href="#二、源码阅读" class="headerlink" title="二、源码阅读"></a>二、源码阅读</h2><h3 id="TwoViewReconstruction-Reconstruct"><a href="#TwoViewReconstruction-Reconstruct" class="headerlink" title="TwoViewReconstruction::Reconstruct()"></a>TwoViewReconstruction::Reconstruct()</h3><p>首先，将该类的成员变量初始化，其中vector容器<code>mvKeys1</code>存储参考帧的特征点，容器<code>mvKeys2</code>存储当前帧的特征点。容器mvMatches12是std::vector<Match>类数据，Match是自定义类型，包含两个int型数据。所以<code>mvMatches12</code>存储的是参考帧的特征点索引值和对应的匹配特征点的索引值。容器<code>mvbMatched1</code>存储参考帧中的特征点是否有匹配点。<code>mvSets</code>是个二维向量，每行是8个特征点的索引值，且互不相同，一共200组。<br>接下来，双线程调用FindHomography()和FindFundamental()函数。通过这两个函数得到F和H矩阵后，比较得分，选择得分高的矩阵来还原R和t。</p>
<hr>
<h3 id="TwoViewReconstruction-FindHomography"><a href="#TwoViewReconstruction-FindHomography" class="headerlink" title="TwoViewReconstruction::FindHomography()"></a>TwoViewReconstruction::FindHomography()</h3><p>首先调用函数Normalize()，将坐标归一化，并得到归一化坐标使用的变换矩阵。然后用归一化后的200组点，对每组点用ComputeH21()函数计算出归一化后H矩阵，再用变换矩阵还原H，使用函数CheckHomography()函数对H打分，最后选择得分最高的H。上面调用的函数，具体原理写在最前面了。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/10/ORBSLAM3-NOTE-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/04/10/ORBSLAM3-NOTE-8/" itemprop="url">ORB-SLAM3源码阅读:ORBmatcher</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-04-10T11:34:02+08:00">
                2023-04-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-8"><a href="#ORBSLAM3学习笔记-8" class="headerlink" title="ORBSLAM3学习笔记(8)"></a>ORBSLAM3学习笔记(8)</h1><p>这篇博客主要是对ORBmatcher.cc文件的学习。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="ORBmatcher-SearchForInitialization"><a href="#ORBmatcher-SearchForInitialization" class="headerlink" title="ORBmatcher::SearchForInitialization()"></a>ORBmatcher::SearchForInitialization()</h3><p><strong>1.创建一个旋转直方图</strong></p>
<pre><code>vector&lt;int&gt; rotHist[HISTO_LENGTH];
// 每个bin里预分配500个，因为使用的是vector不够的话可以自动扩展容量
for(int i=0;i&lt;HISTO_LENGTH;i++)
    rotHist[i].reserve(500);
const float factor = HISTO_LENGTH/360.0f;
</code></pre><p>旋转直方图如下图所示<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/RH.png" alt="旋转直方图"><br>这个直方图就是rotHist，每个柱体就是一个vector容器，称为bin。bin中存储匹配特征点之间的角度差。最后，只取最主流的三个bin，我们只要角度差在这三个范围内的匹配结果，其他的说明特征点角度计算时误差较大，直接舍弃。<br>factor表示每度在整个直方图区间的占比，用来确定角度差的存储在哪个bin里面。</p>
<p><strong>2.在半径窗口内搜索当前帧中所有的候选匹配特征点</strong><br>遍历帧1中的所有特征点(由于这次匹配是用于初始化的，只取金字塔第0层的)</p>
<ul>
<li>在半径窗口内搜索当前帧F2中所有的候选匹配特征点，调用函数GetFeaturesInArea()，具体见<a target="_blank" rel="noopener" href="https://www.jzhblog.top/2023/03/31/ORBSLAM3-NOTE-7/">Frame.cc</a></li>
<li>遍历搜索搜索窗口中的所有潜在的匹配候选点，找到最优的和次优的。匹配的优劣根据描述子的距离判断，两个二进制串之间的汉明距离，指的是其不同位数的个数。</li>
<li>判断最优结果是否满足阈值，判断最佳距离比次佳距离是否小于设定的比例。判断找到的候选特征点对应F1中特征点是否已经匹配过了，如果已经匹配过了，我觉得应该是将这个和原来的匹配都删掉，但源码中是删掉原来的匹配，存入这个新的匹配。如果上面的条件都满足，计算匹配点之间的距离，存入直方图对应的bin中。</li>
</ul>
<p><strong>3.遍历完成，筛除旋转直方图中“非主流”部分</strong></p>
<p><strong>4.将最后通过筛选的匹配好的特征点保存到vbPrevMatched</strong><br>vbPrevMatched是引用参数，将数据保存到该参数中传递回去。</p>
<hr>
<h3 id="ORBmatcher-SearchForTriangulation"><a href="#ORBmatcher-SearchForTriangulation" class="headerlink" title="ORBmatcher::SearchForTriangulation()"></a>ORBmatcher::SearchForTriangulation()</h3><p><strong>1.计算KF1的相机中心在KF2图像平面的二维像素坐标</strong></p>
<blockquote>
<p>直接看我下面的注释就行</p>
</blockquote>
<pre><code>Sophus::SE3f T1w = pKF1-&gt;GetPose();
Sophus::SE3f T2w = pKF2-&gt;GetPose();
Sophus::SE3f Tw2 = pKF2-&gt;GetPoseInverse(); // for convenience
//Cw是关键帧1的光心的世界坐标系下·的坐标
Eigen::Vector3f Cw = pKF1-&gt;GetCameraCenter();
//C2是关键帧1的光心的在关键帧2的坐标系下的坐标
Eigen::Vector3f C2 = T2w * Cw;
//ep是关键帧1的光心在关键帧2上的投影坐标
Eigen::Vector2f ep = pKF2-&gt;mpCamera-&gt;project(C2);
//T12是关键帧2坐标系到关键帧1坐标系的变换矩阵，R12，t12分别存储T12的旋转和平移
Sophus::SE3f T12;
Sophus::SE3f Tll, Tlr, Trl, Trr;
Eigen::Matrix3f R12; // for fastest computation
Eigen::Vector3f t12; // for fastest computation

GeometricCamera* pCamera1 = pKF1-&gt;mpCamera, *pCamera2 = pKF2-&gt;mpCamera;

if(!pKF1-&gt;mpCamera2 &amp;&amp; !pKF2-&gt;mpCamera2)&#123;//单目
    T12 = T1w * Tw2;
    R12 = T12.rotationMatrix();
    t12 = T12.translation();
&#125;
else&#123;//双目
    Sophus::SE3f Tr1w = pKF1-&gt;GetRightPose();
    Sophus::SE3f Twr2 = pKF2-&gt;GetRightPoseInverse();
    Tll = T1w * Tw2;
    Tlr = T1w * Twr2;
    Trl = Tr1w * Tw2;
    Trr = Tr1w * Twr2;
&#125;
Eigen::Matrix3f Rll = Tll.rotationMatrix(), Rlr  = Tlr.rotationMatrix(), Rrl  = Trl.rotationMatrix(), Rrr  = Trr.rotationMatrix();
Eigen::Vector3f tll = Tll.translation(), tlr = Tlr.translation(), trl = Trl.translation(), trr = Trr.translation();

//下面这些参数用处就和上面SearchForInitialization()里面一样了。
int nmatches=0;
// 记录匹配是否成功，避免重复匹配
vector&lt;bool&gt; vbMatched2(pKF2-&gt;N,false);        
vector&lt;int&gt; vMatches12(pKF1-&gt;N,-1);
// 用于统计匹配点对旋转差的直方图
vector&lt;int&gt; rotHist[HISTO_LENGTH];
for(int i=0;i&lt;HISTO_LENGTH;i++)
    rotHist[i].reserve(500);

const float factor = HISTO_LENGTH/360.0f;
</code></pre><p><strong>2.利用BoW加速匹配</strong><br>首先看一下定义的辅助变量</p>
<pre><code>DBoW2::FeatureVector::const_iterator f1it = vFeatVec1.begin();
DBoW2::FeatureVector::const_iterator f2it = vFeatVec2.begin();
DBoW2::FeatureVector::const_iterator f1end = vFeatVec1.end();
DBoW2::FeatureVector::const_iterator f2end = vFeatVec2.end();
</code></pre><p>这里要知道vFeatVec存储了什么，存储的变量是怎么来的，可以看前面推荐的几篇关于词袋方面的博客。</p>
<p>2.1 遍历pKF1和pKF2中的node节点</p>
<blockquote>
<p>首先要进行判断，如果f1it和f2it属于同一个node节点才会进行匹配，这就是BoW加速匹配原理。</p>
</blockquote>
<p>下面讲f1it和f2it属于同一个node节点时该怎么操作</p>
<ol>
<li>遍历该node节点下<strong>f1it</strong>下的所有特征点</li>
<li>通过特征点索引idx1在pKF1中取出对应的MapPoint<blockquote>
<p>若MapPoint存在，则直接进入下一次循环，遍历下一个特征点。若MapPoint不存在，说明该特征点是从未匹配过的。通过这一步骤，我们就能避免重复匹配，导致获得已存在的地图点了。</p>
</blockquote>
</li>
<li>通过特征点索引idx1在pKF1中取出对应的特征点，并取出对应的特征点的描述子。</li>
<li>遍历该node节点下<strong>f2it</strong>对应KF2中的所有特征点</li>
<li>如果pKF2当前特征点索引idx2已经被匹配过或者对应的3d点非空，那么跳过这个索引idx2</li>
<li>通过特征点索引idx2在pKF2中取出对应的特征点和其描述子，计算两个关键帧中对应特征点的描述子距离。</li>
<li><strong>极点ep到kp2的像素距离如果小于阈值th,认为kp2对应的MapPoint距离pKF1相机太近，跳过该匹配点对</strong><blockquote>
<p>作者根据kp2金字塔尺度因子(scale^n，scale=1.2，n为层数)定义阈值th<br> 金字塔层数从0到7，对应距离 sqrt(100*pKF2-&gt;mvScaleFactors[kp2.octave]) 是10-20个像素</p>
</blockquote>
</li>
<li>计算特征点kp2到kp1对应极线的距离是否小于阈值<blockquote>
<p>这个就不细嗦了，这里其实和TwoViewReconstruction.cc那篇博客里的关于F矩阵的卡方检验是一样的。</p>
</blockquote>
</li>
<li>记录匹配结果，记录旋转差直方图信息</li>
</ol>
<p><strong>3.用旋转差直方图来筛掉错误匹配对</strong><br><strong>4.存储匹配关系</strong></p>
<hr>
<h3 id="ORBmatcher-Fuse"><a href="#ORBmatcher-Fuse" class="headerlink" title="ORBmatcher::Fuse()"></a>ORBmatcher::Fuse()</h3><p>该函数的作用是地图点与帧中图像的特征点匹配,实现地图点融合。<br>在将地图点反投影到帧中的过程中,存在以下两种情况:</p>
<ul>
<li>若地图点反投影对应位置上的特征点不存在地图点,说明该特征点之前可能漏掉了，则直接添加观测。</li>
<li>若地图点反投影位置上存在对应地图点,说明两帧中的特征点对应的可能是同一个地图点，但之前出现了误差，则将两个地图点合并到其中观测较多的那个。</li>
</ul>
<p>下面看具体代码：<br>1.获取关键帧（待融合关键帧pKF）位姿、内参、光心在世界坐标系下坐标方便下面使用：Rcw、tcw、fx、fy、cx、cy、bf、Ow。<br>2.遍历所有的待投影地图点，进行如下判断：</p>
<ul>
<li>若该地图点地图点无效 或 已经是该帧的地图点（无需融合），跳过。</li>
<li>将地图点变换到关键帧pKF的相机坐标系下，深度值为负，跳过。</li>
<li>将地图点投影到关键帧pKF的像素坐标系下，若超出了像素坐标系，跳过。</li>
<li>地图点到关键帧相机光心距离需满足在有效范围内，不满足，跳过。</li>
<li>地图点到光心的连线与该地图点的平均观测向量之间夹角要小于60°，不满足跳过。</li>
</ul>
<p>3.在投影点附近搜索窗口内找到候选匹配点的索引</p>
<blockquote>
<p>搜索候选匹配点的索引调用了KeyFrame::GetFeaturesInArea(),这里其实和Frame::GetFeaturesInArea()差不多，具体实现就不细讲了，就讲一下搜索半径怎么来的。<br>首先，根据地图点到光心的距离，得到该点在图像金字塔的层数，然后得到该层的缩放比例，搜索半径就等于th乘以该比例。在orbslam3中，所有th的缺省值都为1。</p>
</blockquote>
<p>4.遍历候选匹配点，寻找最佳匹配点<br>对于每个匹配点，也不是都直接计算描述子距离，首先还要进行判断:</p>
<ul>
<li>金字塔层级要接近（同一层或小一层），否则跳过</li>
<li>计算投影点与候选匹配特征点的距离，进行卡方检验，若超过阈值，直接跳过。</li>
</ul>
<p>若上述判断通过，则计算描述子距离，最后选取距离最小的。<br>5.与最近特征点的描述子距离足够小,就进行地图点融合。</p>
<ul>
<li>地图点反投影位置上存在对应地图点,则将两个地图点合并到其中观测较多的那个则直接添加观测</li>
<li>如果最佳匹配点没有对应地图点，该地图点观测中添加该帧，该帧添加该地图点。</li>
</ul>
<hr>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/31/ORBSLAM3-NOTE-7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/03/31/ORBSLAM3-NOTE-7/" itemprop="url">ORB-SLAM3源码阅读:Frame</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-03-31T21:07:04+08:00">
                2023-03-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-7"><a href="#ORBSLAM3学习笔记-7" class="headerlink" title="ORBSLAM3学习笔记(7)"></a>ORBSLAM3学习笔记(7)</h1><p>这篇博客主要是对Frame.cc文件的学习。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="Frame-Frame-缺省构造"><a href="#Frame-Frame-缺省构造" class="headerlink" title="Frame::Frame() 缺省构造"></a>Frame::Frame() 缺省构造</h3><p>把相关变量赋为空或false，无其他操作。</p>
<hr>
<h3 id="Frame-Frame-const-Frame-amp-frame-拷贝构造"><a href="#Frame-Frame-const-Frame-amp-frame-拷贝构造" class="headerlink" title="Frame::Frame(const Frame &amp;frame) 拷贝构造"></a>Frame::Frame(const Frame &amp;frame) 拷贝构造</h3><p>这里就是把参数frame的数据，拷贝到该对象的成员变量中去。</p>
<hr>
<h3 id="Frame-Frame-…-有参数构造"><a href="#Frame-Frame-…-有参数构造" class="headerlink" title="Frame::Frame(…)有参数构造"></a>Frame::Frame(…)有参数构造</h3><p><strong>1.帧id自加</strong></p>
<pre><code>mnId=nNextId++;
</code></pre><p><strong>2.得图像金字塔的参数，如层数、层间比等</strong><br>这些参数都是从传入的ORBextractor类对象中获取。</p>
<p><strong>3.提取orb特征点</strong></p>
<pre><code>ExtractORB(0,imGray,0,1000);
</code></pre><p>这里调用了ExtractORB()函数，第一个参数是左右标志位，单目相机默认是左边。第二个时灰度图，三四是界限，下面具体看该函数</p>
<pre><code>void Frame::ExtractORB(int flag, const cv::Mat &amp;im, const int x0, const int x1)
&#123;
    vector&lt;int&gt; vLapping = &#123;x0,x1&#125;;
    // 判断是左图还是右图
    if(flag==0)
        // 左图的话就套使用左图指定的特征点提取器，并将提取结果保存到对应的变量中 
        monoLeft = (*mpORBextractorLeft)(im,cv::Mat(),mvKeys,mDescriptors,vLapping);
    else
        // 右图的话就需要使用右图指定的特征点提取器，并将提取结果保存到对应的变量中 
        monoRight = (*mpORBextractorRight)(im,cv::Mat(),mvKeysRight,mDescriptorsRight,vLapping);
&#125;
</code></pre><p>(*mpORBextractorLeft)(im,cv::Mat(),mvKeys,mDescriptors,vLapping);其实就是调用了ORBextractor类的()的重载函数。具体内容可以看<a target="_blank" rel="noopener" href="https://www.jzhblog.top/2023/03/30/ORBSLAM3-NOTE-4/">ORBextractor.cc</a></p>
<p><strong>4.畸变矫正</strong><br>这里就是先把mvKeys存储的特征点的坐标放到一个Mat矩阵里，用opencv库里的函数去其去畸变，把得到的新的坐标覆盖掉mvKeys里的旧数据。去畸变是因为之后要用这些特征点匹配计算位姿变换，我们需要路标点投影到相机平面的正确的坐标。</p>
<pre><code>UndistortKeyPoints();
</code></pre><p>畸变矫正完，由于单目相机无法直接获得立体信息，所以这里要给右图像对应点和深度赋值-1表示没有相关信息</p>
<pre><code>mvuRight = vector&lt;float&gt;(N,-1);
mvDepth = vector&lt;float&gt;(N,-1);
mnCloseMPs = 0;
</code></pre><p><strong>5.初始化本帧的地图点</strong></p>
<pre><code>mvpMapPoints = vector&lt;MapPoint*&gt;(N,static_cast&lt;MapPoint*&gt;(NULL));

mmProjectPoints.clear();// = map&lt;long unsigned int, cv::Point2f&gt;(N, static_cast&lt;cv::Point2f&gt;(NULL));
mmMatchedInImage.clear();
</code></pre><p>这里就是把vector容器的大小初始化了一下，里面没有内容。</p>
<p><strong>6.计算去畸变后图像边界，将特征点分配到网格中。</strong><br>存放特征点的网格mGrid是一个二维数组，数组中的每个元素都是一个vector容器。这个网格是在用来做特征点匹配的，因为暴力匹配的效率实在是有点低，下面看步骤：</p>
<ul>
<li>若图像是第一帧或者是相机标定参数发生变化，则<ul>
<li>计算去畸变后图像的边界，这里也是用opencv库里的函数，这步将mnMinX，mnMaxX，mnMinY，mnMaxY初始化。</li>
<li>计算一个图像像素在网格中占的宽和高mfGridElementWidthInv，mfGridElementHeightInv，这两个变量用来确定特征点在哪个网格。</li>
<li>特殊的初始化过程完成，标志复位mbInitialComputations=false;</li>
</ul>
</li>
<li>设置一些非立体鱼眼模式的标志位  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Nleft = -1;</span><br><span class="line">Nright = -1;</span><br><span class="line">mvLeftToRightMatch = vector&lt;int&gt;(0);</span><br><span class="line">mvRightToLeftMatch = vector&lt;int&gt;(0);</span><br><span class="line">mvStereo3Dpoints = vector&lt;Eigen::Vector3f&gt;(0);</span><br><span class="line">monoLeft = -1;</span><br><span class="line">monoRight = -1;</span><br></pre></td></tr></table></figure></li>
<li>将特征点分配到图像网格中 ，调用函数AssignFeaturesToGrid()</li>
</ul>
<hr>
<h3 id="Frame-AssignFeaturesToGrid"><a href="#Frame-AssignFeaturesToGrid" class="headerlink" title="Frame::AssignFeaturesToGrid()"></a>Frame::AssignFeaturesToGrid()</h3><p><strong>1.给存储特征点的网格数组 Frame::mGrid 预分配空间</strong></p>
<pre><code>const int nCells = FRAME_GRID_COLS*FRAME_GRID_ROWS;

int nReserve = 0.5f*N/(nCells);

// 开始对mGrid这个二维数组中的每一个vector元素遍历并预分配空间
for(unsigned int i=0; i&lt;FRAME_GRID_COLS;i++)
    for (unsigned int j=0; j&lt;FRAME_GRID_ROWS;j++)&#123;
        mGrid[i][j].reserve(nReserve);
        if(Nleft != -1)&#123;
            mGridRight[i][j].reserve(nReserve);
        &#125;
    &#125;
</code></pre><p>这里nReserve定义为0.5f*N/(nCells)，乘以0.5是为了避免内存空间的浪费，反正vector能动态扩容，如果有些格子里的特征点特别多，原来预分配的不够用了，动态申请内存空间就行。</p>
<p><strong>2.遍历每个特征点，将每个特征点在mvKeysUn中的索引值放到对应的网格mGrid中</strong></p>
<pre><code>for(int i=0;i&lt;N;i++)
&#123;
    const cv::KeyPoint &amp;kp = (Nleft == -1) ? mvKeysUn[i]
                                             : (i &lt; Nleft) ? mvKeys[i]
                                                             : mvKeysRight[i - Nleft];
    // 存储某个特征点所在网格的网格坐标，nGridPosX范围：[0,FRAME_GRID_COLS], nGridPosY范围：[0,FRAME_GRID_ROWS]
    int nGridPosX, nGridPosY;
    // 计算某个特征点所在网格的网格坐标，如果找到特征点所在的网格坐标，记录在nGridPosX,nGridPosY里，返回true，没找到返回false
    if(PosInGrid(kp,nGridPosX,nGridPosY))&#123;
        if(Nleft == -1 || i &lt; Nleft)
            // 如果找到特征点所在网格坐标，将这个特征点的索引添加到对应网格的数组mGrid中
            mGrid[nGridPosX][nGridPosY].push_back(i);
        else
            mGridRight[nGridPosX][nGridPosY].push_back(i - Nleft);
    &#125;
&#125;
</code></pre><p>遍历每个关键点，调用PosInGrid()函数，计算出每个关键点在哪个网格，然后将其索引值放入对应网格的vector当中。</p>
<hr>
<h3 id="Frame-GetFeaturesInArea"><a href="#Frame-GetFeaturesInArea" class="headerlink" title="Frame::GetFeaturesInArea()"></a>Frame::GetFeaturesInArea()</h3><p>该函数用来找候选的匹配点，简单来说就是根据需要匹配的点坐标(x,y)和半径r确定边界，遍历在边界内的网格，确认网格内的特征点是第0层的，且在圆内，则把它们push到vector容器中。<br><img src="https://cdn.jsdelivr.net/gh/someone-ob/ImgHosting/PIC/orbslam3/getfeatures.png" alt="获取候选特征点"></p>
<hr>
<h3 id="Frame-isInFrustum"><a href="#Frame-isInFrustum" class="headerlink" title="Frame::isInFrustum()"></a>Frame::isInFrustum()</h3><p>1.获得这个地图点的世界坐标<br>2.检查这个地图点在当前帧的相机坐标系下，是否有正的深度.如果是负的，表示出错，返回false<br>3.将MapPoint投影到当前帧的像素坐标(u,v), 并判断是否在图像有效范围内<br>4.计算MapPoint到相机中心的距离, 并判断是否在尺度变化的距离内</p>
<blockquote>
<p>这里的尺度是0.8 <em> mfMinDistance到1.2 </em> mfMaxDistance，mfMinDistance和mfMaxDistance在Mappoint文件里关于观测距离范围那部分有讲。</p>
</blockquote>
<p>5.计算当前相机指向地图点向量和地图点的平均观测方向夹角的余弦值, 若小于设定阈值，返回false<br>6.根据地图点到光心的距离来预测一个尺度</p>
<blockquote>
<p>这里的尺度是指地图点对应的金字塔层数，公式是$\text{m}=ceil\left( \frac{\log \left( \frac{d_{\max} }{d} \right)}{\log \left( 1.2 \right)} \right)$,可以参考Mappoint.cc里关于观测距离范围那部分。</p>
</blockquote>
<p>7.记录计算得到的一些参数</p>
<pre><code>pMP-&gt;mbTrackInView = true;
// 该地图点投影在当前图像（一般是左图）的像素横坐标
pMP-&gt;mTrackProjX = uv(0);
// bf/z其实是视差，相减得到右图（如有）中对应点的横坐标
pMP-&gt;mTrackProjXR = uv(0) - mbf*invz;

pMP-&gt;mTrackDepth = Pc_dist;

// 该地图点投影在当前图像（一般是左图）的像素纵坐标
pMP-&gt;mTrackProjY = uv(1);
// 根据地图点到光心距离，预测的该地图点的尺度层级
pMP-&gt;mnTrackScaleLevel= nPredictedLevel;
// 保存当前视角和法线夹角的余弦值
pMP-&gt;mTrackViewCos = viewCos;
</code></pre>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/31/ORBSLAM3_NOTE_6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/03/31/ORBSLAM3_NOTE_6/" itemprop="url">ORB-SLAM3源码阅读:LoopClosing</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-03-31T10:41:10+08:00">
                2023-03-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-6"><a href="#ORBSLAM3学习笔记-6" class="headerlink" title="ORBSLAM3学习笔记(6)"></a>ORBSLAM3学习笔记(6)</h1><p>这篇博客主要是对LoopClosing.cc文件的学习。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/30/ORBSLAM3_NOTE_5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2023/03/30/ORBSLAM3_NOTE_5/" itemprop="url">ORB-SLAM3源码阅读:LocalMapping</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-03-30T20:34:51+08:00">
                2023-03-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ORBSLAM3学习笔记-5"><a href="#ORBSLAM3学习笔记-5" class="headerlink" title="ORBSLAM3学习笔记(5)"></a>ORBSLAM3学习笔记(5)</h1><p>这篇博客主要是对LocalMapping.cc文件的学习。现在才看完Tracking线程的初始化部分，由于初始化完之后就有两个关键帧传过来了，所以Tracking线程先放一放，先看一下这个线程。</p>
<hr>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><h3 id="LocalMapping-Run"><a href="#LocalMapping-Run" class="headerlink" title="LocalMapping::Run()"></a>LocalMapping::Run()</h3><p>这里都是已经接收到关键帧后的步骤。<br><strong>1.处理列表中的关键帧，包括计算BoW、更新观测、描述子、共视图，插入到地图等。</strong></p>
<blockquote>
<p>调用函数ProcessNewKeyFrame()</p>
</blockquote>
<p><strong>2.根据地图点的观测情况剔除质量不好的地图点</strong></p>
<blockquote>
<p>调用函数MapPointCulling()</p>
</blockquote>
<p><strong>3.当前关键帧与相邻关键帧通过三角化产生新的地图点，使得跟踪更稳</strong></p>
<blockquote>
<p>调用函数CreateNewMapPoints()</p>
</blockquote>
<p><strong>4.若此时缓冲队列中的关键帧都检测完了，检查并融合当前关键帧与相邻关键帧（两级相邻）帧中重复的地图点</strong></p>
<blockquote>
<p>调用函数SearchInNeighbors()</p>
</blockquote>
<p><strong>5.如果已经处理完队列中的最后的一个关键帧，并且闭环检测没有请求停止LocalMapping，进行局部BA优化</strong></p>
<ul>
<li>当前关键帧的一级共视关键帧位姿会被优化;二极共视关键帧会加入优化图,但其位姿不会被优化。</li>
<li>所有局部地图点位姿都会被优化</li>
</ul>
<p><strong>6.检测并剔除当前帧相邻的关键帧中冗余的关键帧</strong></p>
<blockquote>
<p>调用函数KeyFrameCulling()</p>
</blockquote>
<p><strong>7.将当前帧加入到闭环检测队列中</strong></p>
<hr>
<h3 id="LocalMapping-ProcessNewKeyFrame"><a href="#LocalMapping-ProcessNewKeyFrame" class="headerlink" title="LocalMapping::ProcessNewKeyFrame()"></a>LocalMapping::ProcessNewKeyFrame()</h3><p>这里参考了<a target="_blank" rel="noopener" href="https://blog.csdn.net/ncepu_Chen/article/details/116785093?spm=1001.2014.3001.5502">ORB-SLAM2代码详解08: 局部建图线程LocalMapping</a><br><strong>1.从缓冲队列<code>mlNewKeyFrames</code>中取出一帧关键帧</strong><br><strong>2.计算该关键帧特征点的Bow信息</strong><br><strong>3.通过判断该地图点是否观测到当前关键帧来判断该地图点是否是当前关键帧中新生成的。</strong></p>
<ul>
<li><p>若地图点是本关键帧跟踪过程中匹配得到的(Tracking::TrackWithMotionModel()、Tracking::TrackReferenceKeyFrame()、Tracking::Relocalization()和Tracking::SearchLocalPoints()中调用了ORBmatcher::SearchByProjection()和ORBmatcher::SearchByBoW()方法),则是之前关键帧中创建的地图点,只需添加其对当前帧的观测即可。</p>
</li>
<li><p>若地图点是本关键帧跟踪过程中新生成的(包括:1.单目或双目初始化Tracking::MonocularInitialization()、Tracking::StereoInitialization();2.创建新关键帧Tracking::CreateNewKeyFrame()),则该地图点中有对当前关键帧的观测,是新生成的地图点,放入列表<code>mlpRecentAddedMapPoints</code>中供LocalMapping::MapPointCulling()函数筛选。</p>
</li>
</ul>
<p><strong>4.更新关键帧间的连接关系（共视图）</strong><br><strong>5.将该关键帧插入到地图中</strong></p>
<hr>
<h3 id="LocalMapping-MapPointCulling"><a href="#LocalMapping-MapPointCulling" class="headerlink" title="LocalMapping::MapPointCulling()"></a>LocalMapping::MapPointCulling()</h3><p><strong>1.根据相机类型设置不同的观测阈值</strong></p>
<pre><code>int nThObs;
if(mbMonocular)
    nThObs = 2;
else
    nThObs = 3;
const int cnThObs = nThObs;
</code></pre><p><strong>2.遍历检查的新添加的MapPoints</strong></p>
<blockquote>
<p>从<code>mlpRecentAddedMapPoints</code>获得新添加的点，判断是否需要删掉，总共有四层判断。</p>
<ul>
<li>1.已经是坏点的MapPoints直接从检查链表中删除</li>
<li>2.跟踪到该MapPoint的Frame数相比预计可观测到该MapPoint的Frame数的比例小于25%，删除,<strong>标志位<code>mbToBeErased</code>置为true，这样的话，下次别的帧的该关键点检查时，就可以直接通过第一个判断删掉。</strong><br>代码中的表述为(mnFound/mnVisible） &lt; 0.25<br><code>mnFound</code> ：地图点被多少帧（包括普通帧）看到，次数越多越好<br><code>mnVisible</code>：地图点应该被看到的次数<br>(mnFound/mnVisible）：对于大FOV镜头这个比例会高，对于窄FOV镜头这个比例会低</li>
<li>3.从该点建立开始，到现在已经过了不小于2个关键帧,但是观测到该点的关键帧数却不超过cnThObs帧，那么删除该点，标志位<code>mbToBeErased</code>置为true。</li>
<li>4.从建立该点开始，已经过了3个关键帧而没有被剔除，则认为是质量高的点,因此<strong>没有SetBadFlag()，仅从队列中删除</strong>，放弃继续对该MapPoint的检测。</li>
</ul>
</blockquote>
<hr>
<h3 id="LocalMapping-CreateNewMapPoints"><a href="#LocalMapping-CreateNewMapPoints" class="headerlink" title="LocalMapping::CreateNewMapPoints()"></a>LocalMapping::CreateNewMapPoints()</h3><p>1.在当前关键帧的共视关键帧中找到共视程度最高的nn帧相邻关键帧。</p>
<blockquote>
<p>这里调用了函数GetBestCovisibilityKeyFrames()把相邻关键帧存到了vector<KeyFrame*>类变量vpNeighKFs中。</p>
</blockquote>
<p>2.遍历相邻关键帧vpNeighKFs<br>2.1 判断相机运动的基线是不是足够长</p>
<blockquote>
<p>单目相机情况,计算邻接关键帧的场景深度中值，然后得到基线(即两个光心的距离)与景深的比例，若比例特别小，基线太短恢复3D点不准，那么跳过当前邻接的关键帧，不生成3D点。</p>
</blockquote>
<p>2.2 通过BoW对两关键帧的未匹配的特征点快速匹配，用极线约束抑制离群点，生成新的匹配点对。</p>
<blockquote>
<p>调用函数SearchForTriangulation(),具体看<a target="_blank" rel="noopener" href="https://www.jzhblog.top/2023/04/10/ORBSLAM3-NOTE-8/">ORBmatcher.cc</a>。</p>
</blockquote>
<p>3.遍历匹配点，每对匹配通过三角化生成3D点<br>3.1 获得当前关键帧和邻接关键帧中的匹配特征点。<br>3.2 利用匹配点反投影得到视差角</p>
<blockquote>
<p>这里先通过像素坐标得到相机坐标系下的路标点坐标\[X\text{=}\frac{\text{u}-c_x}{f_x},Y=\frac{v-c_y}{f_y},Z=1\]再把它们都转化成世界坐标下的(这里只用旋转坐标就行了，毕竟深度还未确定，平移没什么意义)，计算两个向量的cos值，即视角差。</p>
</blockquote>
<p>3.3 用三角法恢复3D点(这里和单目初始化时一样)<br>3.4 检测生成的3D点是否在相机前方,不在的话就放弃这个点<br>3.5 计算3D点在当前关键帧和邻接关键帧下的重投影误差，用卡方检验，超出阈值则放弃。<br>3.6 检查尺度连续性</p>
<blockquote>
<p>计算路标点到两帧光心的距离d1,d2。得到特征点在两帧中的图像金字塔中的层数的对应缩放比例s1,s2。ratioDist = d2/d1，ratioOctave=s1/s2,ratioFactor = 1.5f<em>1.2(1.2就是基础缩放比例);若ratioDist\</em>ratioFactor&lt; ratioOctave或ratioDist&gt;ratioOctave*ratioFactor,说明距离的比例和图像金字塔的比例相差太多，跳过。</p>
</blockquote>
<p>3.7 构造地图点，为地图点添加属性，分别是</p>
<ul>
<li>观测到该MapPoint的关键帧</li>
<li>该MapPoint的描述子</li>
<li>该MapPoint的平均观测方向和深度范围</li>
</ul>
<p>这些前面都讲过了，看<a target="_blank" rel="noopener" href="https://www.jzhblog.top/2023/04/13/ORBSLAM3-NOTE-11/">MapPoint.cc</a>就行。<br>3.8 把该新生成的地图点放入<code>mlpRecentAddedMapPoints</code>中。</p>
<hr>
<h3 id="LocalMapping-SearchInNeighbors"><a href="#LocalMapping-SearchInNeighbors" class="headerlink" title="LocalMapping::SearchInNeighbors()"></a>LocalMapping::SearchInNeighbors()</h3><p>1.获得当前关键帧在共视图中权重排名前20的邻接关键帧<br>2.存储一级相邻关键帧及其二级相邻关键帧</p>
<blockquote>
<p>一级关键帧就是第一步中的那20个邻接关键帧，二级关键帧就是遍历一级关键帧，取他们在共视图中权重排名前5的邻接关键帧。一二级邻接关键帧都存储在vpTargetKFs中，且所有相邻关键帧的成员变量<code>mnFuseTargetForKF</code>都要改为mpCurrentKeyFrame-&gt;mnId以作标记，避免重复选取。</p>
</blockquote>
<p>3.将当前帧的地图点分别与一级二级相邻关键帧地图点进行融合 — 正向</p>
<blockquote>
<p>调用函数ORBmatcher::Fuse()，详情见<a target="_blank" rel="noopener" href="https://www.jzhblog.top/2023/04/10/ORBSLAM3-NOTE-8/">ORBmatcher.cc</a></p>
</blockquote>
<p>4.将一级二级相邻关键帧地图点分别与当前关键帧地图点进行融合 — 反向</p>
<ul>
<li>4.1 遍历每一个一级邻接和二级邻接关键帧，收集他们的地图点存储到 vpFuseCandidates</li>
<li>4.2 进行地图点投影融合,和正向融合操作是完全相同的</li>
</ul>
<p>5.更新当前帧地图点的描述子、深度、观测主方向等属性<br>6.更新当前帧的MapPoints后更新与其它帧的连接关系</p>
<blockquote>
<p>即更新共视关系，调用函数KeyFrame::UpdateConnections()</p>
</blockquote>
<hr>
<h3 id="LocalMapping-KeyFrameCulling"><a href="#LocalMapping-KeyFrameCulling" class="headerlink" title="LocalMapping::KeyFrameCulling()"></a>LocalMapping::KeyFrameCulling()</h3><p>先获取当前关键帧mpCurrentKeyFrame的一级共视关键帧vpLocalKeyFrames。<br>对所有的共视关键帧vpLocalKeyFrames进行遍历：</p>
<p>遍历到的关键帧为pKF，规定第一个关键帧不能删除（初始化的第一帧），提取每个共视关键帧的地图点vpMapPoints（vpLocalKeyFrames的地图点），遍历每一个地图点：</p>
<p>如果该地图点的被观测次数超过阈值thObs，获取能看见该地图点的关键帧的集合observations，遍历观测到该地图点的关键帧，获得该地图点在关键帧中对应的特征点在图像金字塔的层数，若层数不超过其在pKF中的层数，则nObs++，最后若nObs&gt;3,则该地图点为冗余地图点。</p>
<p>如果该关键帧90%以上的有效地图点被判断为冗余的，则认为该关键帧是冗余的，需要删除该关键帧。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">&gt;</a>
  </nav>


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
